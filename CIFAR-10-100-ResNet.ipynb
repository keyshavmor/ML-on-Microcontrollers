{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a13fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/themandalorian/anaconda3/envs/dl-gpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow==2.10 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (2.10.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.24.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.54.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: packaging in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (23.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (3.8.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (4.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (66.0.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (0.32.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (23.3.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (3.19.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorflow==2.10) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/themandalorian/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "57a89863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "026513a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "data_path = 'cifar-10-batches-py/'\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(data_path + 'data_batch_' + str(i))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3df4baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data = unpickle(data_path + 'test_batch')[b'data']\n",
    "test_data = test_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(unpickle(data_path + 'test_batch')[b'labels'])\n",
    "#train_labels = to_categorical(train_labels)\n",
    "#test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "data_path = 'cifar-100-python/'\n",
    "train_data_100 = unpickle(data_path + 'train')[b'data']\n",
    "train_data_100 = train_data_100.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data_100 = unpickle(data_path + 'test')[b'data']\n",
    "test_data_100 = test_data_100.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels_100 = np.array(unpickle(data_path + 'train')[b'fine_labels'])\n",
    "test_labels_100 = np.array(unpickle(data_path + 'test')[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "52dc16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 10\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "print(\"CIFAR-10\")\n",
    "print(\"Number of features:\", train_data.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "print(\"Number of training samples:\", train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "bdf5dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CIFAR-100\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 100\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-100\n",
    "print(\"\\nCIFAR-100\")\n",
    "print(\"Number of features:\", train_data_100.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels_100)))\n",
    "print(\"Number of training samples:\", train_data_100.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8442624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=42)\n",
    "train_data_100, train_labels_100 = shuffle(train_data_100, train_labels_100, random_state=42)\n",
    "test_data, test_labels = shuffle(test_data, test_labels, random_state=42)\n",
    "test_data_100, test_labels_100 = shuffle(test_data_100, test_labels_100, random_state=42)\n",
    "\n",
    "# Get the number of classes in the dataset\n",
    "#num_classes = len(np.unique(train_labels))\n",
    "\n",
    "# Initialize empty lists to store the indices of the selected examples\n",
    "#selected_train_indices = []\n",
    "#selected_test_indices = []\n",
    "\n",
    "# Loop over each class\n",
    "#for i in range(num_classes):\n",
    "    # Get the indices of the examples belonging to the current class in the training dataset\n",
    "#    class_train_indices = np.where(train_labels == i)[0]\n",
    "    # Randomly choose 10% examples from the current class in the training dataset\n",
    "#    selected_train_indices.extend(np.random.choice(class_train_indices, size=int(len(class_train_indices)*0.1), replace=False))\n",
    "\n",
    "    # Get the indices of the examples belonging to the current class in the test dataset\n",
    "#    class_test_indices = np.where(test_labels == i)[0]\n",
    "    # Randomly choose 10% examples from the current class in the test dataset\n",
    "#    selected_test_indices.extend(np.random.choice(class_test_indices, size=int(len(class_test_indices)*0.1), replace=False))\n",
    "\n",
    "# Select the 10% examples from the training and test datasets using the selected indices\n",
    "#train_data = train_data[selected_train_indices]\n",
    "#train_labels = train_labels[selected_train_indices]\n",
    "#test_data = test_data[selected_test_indices]\n",
    "#test_labels = test_labels[selected_test_indices]\n",
    "\n",
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "#print(\"CIFAR-10\")\n",
    "#print(\"Number of features:\", train_data.shape[1:])\n",
    "#print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "#print(\"Number of training samples:\", train_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "efc13d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "x_train = train_data.astype('float32') / 255.0\n",
    "x_test = test_data.astype('float32') / 255.0\n",
    "x_train_100 = train_data_100.astype('float32') / 255.0\n",
    "x_test_100 = test_data_100.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(test_labels, num_classes=10)\n",
    "y_train_100 = to_categorical(train_labels_100, num_classes=100)\n",
    "y_test_100 = to_categorical(test_labels_100, num_classes=100)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(x_train, y_train, batch_size=64)\n",
    "# fit model\n",
    "steps = int(x_train.shape[0] / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f68917df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build ResNet-50 model\n",
    "base_model = ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_10 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10.{epoch:02d}.h5', save_freq='epoch')\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the epoch number.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.001\n",
    "    if epoch > 2:\n",
    "        learning_rate = 0.00075\n",
    "    if epoch > 4:\n",
    "        learning_rate = 0.0005\n",
    "    if epoch > 6:\n",
    "        learning_rate = 0.00025\n",
    "    if epoch > 8:\n",
    "        learning_rate = 0.000125\n",
    "    if epoch > 8:\n",
    "        learning_rate = 0.0000625\n",
    "    if epoch > 10:\n",
    "        learning_rate = 0.00003125\n",
    "    if epoch > 12:\n",
    "        learning_rate = 0.000015\n",
    "    if epoch > 15:\n",
    "        learning_rate = 0.0000075\n",
    "    return learning_rate\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model_10.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4afe356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "781/781 [==============================] - 724s 916ms/step - loss: 0.7830 - accuracy: 0.7259 - val_loss: 0.8284 - val_accuracy: 0.7152 - lr: 1.2500e-04\n",
      "Epoch 2/11\n",
      "781/781 [==============================] - 697s 892ms/step - loss: 0.7381 - accuracy: 0.7429 - val_loss: 1.0076 - val_accuracy: 0.6696 - lr: 1.2500e-04\n",
      "Epoch 3/11\n",
      "781/781 [==============================] - 698s 894ms/step - loss: 0.7049 - accuracy: 0.7522 - val_loss: 0.7491 - val_accuracy: 0.7462 - lr: 1.2500e-04\n",
      "Epoch 4/11\n",
      "781/781 [==============================] - 712s 912ms/step - loss: 0.6501 - accuracy: 0.7715 - val_loss: 0.6858 - val_accuracy: 0.7677 - lr: 6.2500e-05\n",
      "Epoch 5/11\n",
      "781/781 [==============================] - 709s 908ms/step - loss: 0.6310 - accuracy: 0.7798 - val_loss: 1.1641 - val_accuracy: 0.6407 - lr: 6.2500e-05\n",
      "Epoch 6/11\n",
      "781/781 [==============================] - 723s 925ms/step - loss: 0.6158 - accuracy: 0.7859 - val_loss: 0.6607 - val_accuracy: 0.7726 - lr: 3.1250e-05\n",
      "Epoch 7/11\n",
      "781/781 [==============================] - 729s 933ms/step - loss: 0.5913 - accuracy: 0.7925 - val_loss: 0.7051 - val_accuracy: 0.7639 - lr: 3.1250e-05\n",
      "Epoch 8/11\n",
      "781/781 [==============================] - 722s 924ms/step - loss: 0.5787 - accuracy: 0.7964 - val_loss: 0.6699 - val_accuracy: 0.7727 - lr: 1.5000e-05\n",
      "Epoch 9/11\n",
      "781/781 [==============================] - 758s 970ms/step - loss: 0.5724 - accuracy: 0.7982 - val_loss: 0.6486 - val_accuracy: 0.7804 - lr: 1.5000e-05\n",
      "Epoch 10/11\n",
      "781/781 [==============================] - 758s 970ms/step - loss: 0.5637 - accuracy: 0.8025 - val_loss: 0.6547 - val_accuracy: 0.7799 - lr: 7.5000e-06\n",
      "Epoch 11/11\n",
      "781/781 [==============================] - 788s 1s/step - loss: 0.5624 - accuracy: 0.8024 - val_loss: 0.6484 - val_accuracy: 0.7809 - lr: 7.5000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35eb31d970>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "learning_rate = 0.000125\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule_new(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the epoch number.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.000125\n",
    "    if epoch >= 1:\n",
    "        learning_rate = 0.000125\n",
    "    if epoch >= 3:\n",
    "        learning_rate = 0.0000625\n",
    "    if epoch >= 5:\n",
    "        learning_rate = 0.00003125\n",
    "    if epoch >= 7:\n",
    "        learning_rate = 0.000015\n",
    "    if epoch >= 9:\n",
    "        learning_rate = 0.0000075\n",
    "    return learning_rate\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule_new)\n",
    "\n",
    "# load the pre-saved model\n",
    "model_10 = load_model('model_10.09.h5')\n",
    "\n",
    "model_10.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model.{epoch:02d}.h5', save_freq='epoch')\n",
    "\n",
    "# Model Fit\n",
    "model_10.fit(it_train, steps_per_epoch=steps, epochs=11, validation_data=(x_test, y_test), \n",
    "             callbacks=[lr_scheduler,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ab404a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 78ms/step - loss: 0.6484 - accuracy: 0.7809\n",
      "Test accuracy: 0.7809000015258789\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on the test set\n",
    "loss, accuracy = model_10.evaluate(x_test, y_test)\n",
    "\n",
    "# print the accuracy of the model on the test set\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118937a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
