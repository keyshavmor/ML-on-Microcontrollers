{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ad436e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "GPU (s):\n",
      "0.04505607499595499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:16:50.870982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 14:16:50.871263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 14:16:50.871460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 14:16:50.871717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 14:16:50.871921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 14:16:50.872074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 5802 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "305e8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75d7c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "data_path = 'cifar-10-batches-py/'\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(data_path + 'data_batch_' + str(i))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "496d35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data = unpickle(data_path + 'test_batch')[b'data']\n",
    "test_data = test_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(unpickle(data_path + 'test_batch')[b'labels'])\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "data_path = 'cifar-100-python/'\n",
    "train_data_100 = unpickle(data_path + 'train')[b'data']\n",
    "train_data_100 = train_data_100.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data_100 = unpickle(data_path + 'test')[b'data']\n",
    "test_data_100 = test_data_100.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels_100 = np.array(unpickle(data_path + 'train')[b'fine_labels'])\n",
    "test_labels_100 = np.array(unpickle(data_path + 'test')[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d5a372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 10\n",
      "Number of training samples: 50000\n",
      "\n",
      "CIFAR-100\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 100\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "print(\"CIFAR-10\")\n",
    "print(\"Number of features:\", train_data.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "print(\"Number of training samples:\", train_data.shape[0])\n",
    "\n",
    "# Print the number of features, classes, and training samples for CIFAR-100\n",
    "print(\"\\nCIFAR-100\")\n",
    "print(\"Number of features:\", train_data_100.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels_100)))\n",
    "print(\"Number of training samples:\", train_data_100.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e294dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=42)\n",
    "test_data, test_labels = shuffle(test_data, test_labels, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = train_data.astype('float32') / 255.0\n",
    "x_test = test_data.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(zoom_range=[0.5,1.5],\n",
    "                             brightness_range=[0.25,1.0],\n",
    "                             shear_range=0.5,\n",
    "                             width_shift_range=0.5, \n",
    "                             height_shift_range=0.5,\n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(x_train, y_train, batch_size=64)\n",
    "# fit model\n",
    "steps = int(x_train.shape[0] / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76844843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_9 (QuantizeL  (None, 32, 32, 3)        3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_conv2d_58 (QuantizeWr  (None, 32, 32, 32)       963       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_59 (QuantizeWr  (None, 32, 32, 32)       9315      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_24 (Qua  (None, 16, 16, 32)       1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_60 (QuantizeWr  (None, 16, 16, 64)       18627     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_61 (QuantizeWr  (None, 16, 16, 64)       37059     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_25 (Qua  (None, 8, 8, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_62 (QuantizeWr  (None, 8, 8, 128)        74115     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_63 (QuantizeWr  (None, 8, 8, 128)        147843    \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_26 (Qua  (None, 4, 4, 128)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_9 (QuantizeWr  (None, 2048)             1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dense_18 (QuantizeWra  (None, 128)              262277    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_19 (QuantizeWra  (None, 10)               1295      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551,501\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 931\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.6224 - accuracy: 0.4094 - val_loss: 1.2819 - val_accuracy: 0.5429 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 1.0884 - accuracy: 0.6140 - val_loss: 0.9546 - val_accuracy: 0.6697 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.8706 - accuracy: 0.6956 - val_loss: 0.9172 - val_accuracy: 0.6779 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.7320 - accuracy: 0.7439 - val_loss: 0.8029 - val_accuracy: 0.7272 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6210 - accuracy: 0.7821 - val_loss: 0.8089 - val_accuracy: 0.7345 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5401 - accuracy: 0.8112 - val_loss: 0.7507 - val_accuracy: 0.7504 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4602 - accuracy: 0.8361 - val_loss: 0.8016 - val_accuracy: 0.7428 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3917 - accuracy: 0.8612 - val_loss: 0.8161 - val_accuracy: 0.7526 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3388 - accuracy: 0.8797 - val_loss: 0.9435 - val_accuracy: 0.7336 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3088 - accuracy: 0.8904 - val_loss: 0.9552 - val_accuracy: 0.7439 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2679 - accuracy: 0.9061 - val_loss: 0.9642 - val_accuracy: 0.7440 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2328 - accuracy: 0.9178 - val_loss: 0.9966 - val_accuracy: 0.7580 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2209 - accuracy: 0.9232 - val_loss: 1.1324 - val_accuracy: 0.7535 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2198 - accuracy: 0.9228 - val_loss: 1.0893 - val_accuracy: 0.7485 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1916 - accuracy: 0.9325 - val_loss: 1.0620 - val_accuracy: 0.7558 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1874 - accuracy: 0.9361 - val_loss: 1.2282 - val_accuracy: 0.7442 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1793 - accuracy: 0.9380 - val_loss: 1.0751 - val_accuracy: 0.7528 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1612 - accuracy: 0.9450 - val_loss: 1.2639 - val_accuracy: 0.7561 - lr: 0.0100\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1749 - accuracy: 0.9393 - val_loss: 1.2116 - val_accuracy: 0.7453 - lr: 0.0100\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1652 - accuracy: 0.9444 - val_loss: 1.3085 - val_accuracy: 0.7504 - lr: 0.0100\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1471 - accuracy: 0.9509 - val_loss: 1.4344 - val_accuracy: 0.7488 - lr: 0.0100\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1518 - accuracy: 0.9497 - val_loss: 1.2355 - val_accuracy: 0.7513 - lr: 0.0100\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 1.2698 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 1.3759 - val_accuracy: 0.7821 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 1.4602 - val_accuracy: 0.7843 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 1.5172 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 1.5678 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.6022 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6459 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6740 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 9.0955e-04 - accuracy: 1.0000 - val_loss: 1.7026 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 7.9279e-04 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.7869 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 6.9523e-04 - accuracy: 1.0000 - val_loss: 1.7433 - val_accuracy: 0.7881 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 6.2373e-04 - accuracy: 1.0000 - val_loss: 1.7632 - val_accuracy: 0.7867 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 5.5982e-04 - accuracy: 1.0000 - val_loss: 1.7861 - val_accuracy: 0.7888 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 5.0665e-04 - accuracy: 1.0000 - val_loss: 1.8072 - val_accuracy: 0.7871 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 4.5887e-04 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.7877 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 4.2303e-04 - accuracy: 1.0000 - val_loss: 1.8396 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 3.9281e-04 - accuracy: 1.0000 - val_loss: 1.8512 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 3.7432e-04 - accuracy: 1.0000 - val_loss: 1.8700 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 3.3943e-04 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.7893 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 3.2213e-04 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.9703e-04 - accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.8034e-04 - accuracy: 1.0000 - val_loss: 1.9215 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.6661e-04 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 2.5232e-04 - accuracy: 1.0000 - val_loss: 1.9435 - val_accuracy: 0.7888 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.3768e-04 - accuracy: 1.0000 - val_loss: 1.9494 - val_accuracy: 0.7896 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.2633e-04 - accuracy: 1.0000 - val_loss: 1.9567 - val_accuracy: 0.7891 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.2049e-04 - accuracy: 1.0000 - val_loss: 1.9695 - val_accuracy: 0.7885 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 2.0734e-04 - accuracy: 1.0000 - val_loss: 1.9806 - val_accuracy: 0.7885 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb42256c10>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_10.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT.h5', save_freq='epoch')\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
    "                                factor=0.1,\n",
    "                                patience=10,\n",
    "                                verbose=0,\n",
    "                                mode=\"max\",\n",
    "                                min_delta=0.0001,\n",
    "                                cooldown=0,\n",
    "                                min_lr=0.001)\n",
    "\n",
    "# Convert the model to a quantization aware model\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(model_10)\n",
    "\n",
    "quant_aware_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "quant_aware_model.summary()\n",
    "\n",
    "# Train and evaluate the quantization aware model\n",
    "quant_aware_model.fit(x_train,y_train,batch_size=64,epochs=50,validation_data=(x_test, y_test),callbacks=[checkpoint_callback,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "affed6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization aware training loss:  1.980594277381897\n",
      "Quantization aware training accuracy:  0.7885000109672546\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "quant_loss, quant_acc = quant_aware_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Quantization aware training loss: ', quant_loss)\n",
    "print('Quantization aware training accuracy: ', quant_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "058c511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_58_layer_call_fn, conv2d_58_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_59_layer_call_fn, conv2d_59_layer_call_and_return_conditional_losses while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpayrvpps3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpayrvpps3/assets\n",
      "/home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-05-09 14:33:42.220128: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-09 14:33:42.220155: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-09 14:33:42.220322: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpayrvpps3\n",
      "2023-05-09 14:33:42.225188: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-09 14:33:42.225207: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpayrvpps3\n",
      "2023-05-09 14:33:42.244851: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-09 14:33:42.331436: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpayrvpps3\n",
      "2023-05-09 14:33:42.353369: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 133046 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8_qat = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "440cd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "571288"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"cifar10_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb0dbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_conv2d_58_input:0\n",
      "shape: [ 1 32 32  3]\n",
      "type: <class 'numpy.uint8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter('cifar10_qat_int8.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "082e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(x_test),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(x_test)):\n",
    "    val_batch = x_test[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f22e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 78.86999999999999%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f450c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
