{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ad436e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "GPU (s):\n",
      "0.044843599000159884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 04:31:41.342147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 04:31:41.342325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 04:31:41.342437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 04:31:41.342599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 04:31:41.342715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 04:31:41.342808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 5600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "305e8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75d7c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "data_path = 'cifar-10-batches-py/'\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(data_path + 'data_batch_' + str(i))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "496d35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data = unpickle(data_path + 'test_batch')[b'data']\n",
    "test_data = test_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(unpickle(data_path + 'test_batch')[b'labels'])\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "data_path = 'cifar-100-python/'\n",
    "train_data_100 = unpickle(data_path + 'train')[b'data']\n",
    "train_data_100 = train_data_100.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data_100 = unpickle(data_path + 'test')[b'data']\n",
    "test_data_100 = test_data_100.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels_100 = np.array(unpickle(data_path + 'train')[b'fine_labels'])\n",
    "test_labels_100 = np.array(unpickle(data_path + 'test')[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d5a372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 10\n",
      "Number of training samples: 50000\n",
      "\n",
      "CIFAR-100\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 100\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "print(\"CIFAR-10\")\n",
    "print(\"Number of features:\", train_data.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "print(\"Number of training samples:\", train_data.shape[0])\n",
    "\n",
    "# Print the number of features, classes, and training samples for CIFAR-100\n",
    "print(\"\\nCIFAR-100\")\n",
    "print(\"Number of features:\", train_data_100.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels_100)))\n",
    "print(\"Number of training samples:\", train_data_100.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e294dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=42)\n",
    "train_data_100, train_labels_100 = shuffle(train_data_100, train_labels_100, random_state=42)\n",
    "test_data, test_labels = shuffle(test_data, test_labels, random_state=42)\n",
    "test_data_100, test_labels_100 = shuffle(test_data_100, test_labels_100, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = train_data.astype('float32') / 255.0\n",
    "x_test = test_data.astype('float32') / 255.0\n",
    "x_train_100 = train_data_100.astype('float32') / 255.0\n",
    "x_test_100 = test_data_100.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(test_labels, num_classes=10)\n",
    "y_train_100 = to_categorical(train_labels_100, num_classes=100)\n",
    "y_test_100 = to_categorical(test_labels_100, num_classes=100)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(x_train, y_train, batch_size=64)\n",
    "# fit model\n",
    "steps = int(x_train.shape[0] / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76844843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build ResNet-50 model\n",
    "#base_model = ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3))\n",
    "#x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "#predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Dropout(0.2))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Dropout(0.3))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Dropout(0.4))\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(10, activation='softmax'))\n",
    "# compile model\n",
    "opt = SGD(lr=0.001, momentum=0.9)\n",
    "model_10.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model_10 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_gpu.{epoch:02d}.h5', save_freq='epoch')\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the epoch number.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.001\n",
    "    if (epoch>1 and epoch<=3):\n",
    "        learning_rate = 0.00075\n",
    "    if (epoch>3 and epoch<=5):\n",
    "        learning_rate = 0.0005\n",
    "    if (epoch>5 and epoch<=7):\n",
    "        learning_rate = 0.00025\n",
    "    if (epoch>7 and epoch<=9):\n",
    "        learning_rate = 0.000125\n",
    "    if (epoch>9 and epoch<=11):\n",
    "        learning_rate = 0.0000625\n",
    "    if (epoch>11 and epoch<=13):\n",
    "        learning_rate = 0.00003125\n",
    "    if (epoch>13 and epoch<= 15):\n",
    "        learning_rate = 0.00001575\n",
    "    if (epoch>15):\n",
    "        learning_rate = 0.000007375\n",
    "    return learning_rate\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "#model_10.compile(optimizer=SGD(learning_rate=learning_rate, momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "affed6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "781/781 [==============================] - 15s 18ms/step - loss: 2.1393 - accuracy: 0.2986 - val_loss: 1.4816 - val_accuracy: 0.4613\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.6165 - accuracy: 0.4080 - val_loss: 1.4033 - val_accuracy: 0.4932\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.4910 - accuracy: 0.4538 - val_loss: 1.3270 - val_accuracy: 0.5201\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.4223 - accuracy: 0.4832 - val_loss: 1.3085 - val_accuracy: 0.5318\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 1.3714 - accuracy: 0.5031 - val_loss: 1.4290 - val_accuracy: 0.4899\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 1.3174 - accuracy: 0.5235 - val_loss: 1.3309 - val_accuracy: 0.5151\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.2740 - accuracy: 0.5414 - val_loss: 1.2229 - val_accuracy: 0.5527\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.2361 - accuracy: 0.5548 - val_loss: 1.2378 - val_accuracy: 0.5605\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 1.1973 - accuracy: 0.5658 - val_loss: 1.1661 - val_accuracy: 0.5855\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.1662 - accuracy: 0.5808 - val_loss: 1.2257 - val_accuracy: 0.5652\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.1436 - accuracy: 0.5895 - val_loss: 1.2448 - val_accuracy: 0.5631\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.1136 - accuracy: 0.6000 - val_loss: 1.3001 - val_accuracy: 0.5529\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.0958 - accuracy: 0.6100 - val_loss: 1.0558 - val_accuracy: 0.6244\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.0696 - accuracy: 0.6176 - val_loss: 1.2061 - val_accuracy: 0.5811\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.0487 - accuracy: 0.6243 - val_loss: 1.1928 - val_accuracy: 0.5910\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 1.0280 - accuracy: 0.6333 - val_loss: 1.0967 - val_accuracy: 0.6196\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 1.0118 - accuracy: 0.6388 - val_loss: 1.0050 - val_accuracy: 0.6460\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.9909 - accuracy: 0.6489 - val_loss: 0.9582 - val_accuracy: 0.6626\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.9769 - accuracy: 0.6530 - val_loss: 0.9670 - val_accuracy: 0.6598\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.9630 - accuracy: 0.6593 - val_loss: 1.0536 - val_accuracy: 0.6333\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.9475 - accuracy: 0.6643 - val_loss: 0.9410 - val_accuracy: 0.6717\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.9266 - accuracy: 0.6706 - val_loss: 0.9621 - val_accuracy: 0.6637\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.9090 - accuracy: 0.6794 - val_loss: 0.9619 - val_accuracy: 0.6610\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.9032 - accuracy: 0.6816 - val_loss: 0.8849 - val_accuracy: 0.6900\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8904 - accuracy: 0.6876 - val_loss: 0.8568 - val_accuracy: 0.6961\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.8787 - accuracy: 0.6911 - val_loss: 0.9541 - val_accuracy: 0.6677\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.8624 - accuracy: 0.6987 - val_loss: 0.8769 - val_accuracy: 0.6901\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8540 - accuracy: 0.6983 - val_loss: 0.8236 - val_accuracy: 0.7082\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.8493 - accuracy: 0.7050 - val_loss: 0.8789 - val_accuracy: 0.6964\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8367 - accuracy: 0.7094 - val_loss: 0.8534 - val_accuracy: 0.7011\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.8329 - accuracy: 0.7110 - val_loss: 0.8257 - val_accuracy: 0.7129\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.8220 - accuracy: 0.7136 - val_loss: 0.8517 - val_accuracy: 0.7000\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.8168 - accuracy: 0.7144 - val_loss: 0.8346 - val_accuracy: 0.7135\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8073 - accuracy: 0.7184 - val_loss: 0.8298 - val_accuracy: 0.7087\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7967 - accuracy: 0.7204 - val_loss: 0.7952 - val_accuracy: 0.7177\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.7851 - accuracy: 0.7250 - val_loss: 0.8832 - val_accuracy: 0.6985\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7837 - accuracy: 0.7258 - val_loss: 0.7904 - val_accuracy: 0.7257\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7700 - accuracy: 0.7304 - val_loss: 0.7532 - val_accuracy: 0.7335\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7707 - accuracy: 0.7302 - val_loss: 0.8252 - val_accuracy: 0.7104\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7599 - accuracy: 0.7349 - val_loss: 0.7234 - val_accuracy: 0.7438\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.7604 - accuracy: 0.7349 - val_loss: 0.8156 - val_accuracy: 0.7185\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.7484 - accuracy: 0.7380 - val_loss: 0.7514 - val_accuracy: 0.7364\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7397 - accuracy: 0.7443 - val_loss: 0.7226 - val_accuracy: 0.7456\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.7407 - accuracy: 0.7424 - val_loss: 0.7212 - val_accuracy: 0.7461\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7251 - accuracy: 0.7489 - val_loss: 0.7311 - val_accuracy: 0.7431\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7225 - accuracy: 0.7495 - val_loss: 0.7025 - val_accuracy: 0.7540\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.7206 - accuracy: 0.7484 - val_loss: 0.6715 - val_accuracy: 0.7641\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7207 - accuracy: 0.7498 - val_loss: 0.6907 - val_accuracy: 0.7572\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7080 - accuracy: 0.7553 - val_loss: 0.6900 - val_accuracy: 0.7592\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.7039 - accuracy: 0.7557 - val_loss: 0.7179 - val_accuracy: 0.7495\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6975 - accuracy: 0.7582 - val_loss: 0.7310 - val_accuracy: 0.7427\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6881 - accuracy: 0.7611 - val_loss: 0.6889 - val_accuracy: 0.7601\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6889 - accuracy: 0.7603 - val_loss: 0.7715 - val_accuracy: 0.7351\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6837 - accuracy: 0.7635 - val_loss: 0.6671 - val_accuracy: 0.7680\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6749 - accuracy: 0.7665 - val_loss: 0.7109 - val_accuracy: 0.7491\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6762 - accuracy: 0.7650 - val_loss: 0.6194 - val_accuracy: 0.7818\n",
      "Epoch 57/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6708 - accuracy: 0.7675 - val_loss: 0.6327 - val_accuracy: 0.7783\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6677 - accuracy: 0.7685 - val_loss: 0.6639 - val_accuracy: 0.7660\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.6591 - accuracy: 0.7733 - val_loss: 0.6768 - val_accuracy: 0.7638\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6527 - accuracy: 0.7731 - val_loss: 0.6441 - val_accuracy: 0.7774\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6554 - accuracy: 0.7737 - val_loss: 0.6181 - val_accuracy: 0.7847\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6448 - accuracy: 0.7776 - val_loss: 0.6407 - val_accuracy: 0.7763\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6402 - accuracy: 0.7797 - val_loss: 0.6773 - val_accuracy: 0.7635\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.6416 - accuracy: 0.7803 - val_loss: 0.5988 - val_accuracy: 0.7896\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6342 - accuracy: 0.7810 - val_loss: 0.6228 - val_accuracy: 0.7831\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6347 - accuracy: 0.7798 - val_loss: 0.6023 - val_accuracy: 0.7877\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6353 - accuracy: 0.7809 - val_loss: 0.6140 - val_accuracy: 0.7894\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6230 - accuracy: 0.7846 - val_loss: 0.6117 - val_accuracy: 0.7879\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6209 - accuracy: 0.7866 - val_loss: 0.5656 - val_accuracy: 0.8023\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6249 - accuracy: 0.7851 - val_loss: 0.6244 - val_accuracy: 0.7840\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.6211 - accuracy: 0.7852 - val_loss: 0.6045 - val_accuracy: 0.7867\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 0.6142 - accuracy: 0.7873 - val_loss: 0.5892 - val_accuracy: 0.7930\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6099 - accuracy: 0.7878 - val_loss: 0.5846 - val_accuracy: 0.7939\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6016 - accuracy: 0.7918 - val_loss: 0.6716 - val_accuracy: 0.7721\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6049 - accuracy: 0.7915 - val_loss: 0.5765 - val_accuracy: 0.7979\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6009 - accuracy: 0.7929 - val_loss: 0.5940 - val_accuracy: 0.7913\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5966 - accuracy: 0.7941 - val_loss: 0.6481 - val_accuracy: 0.7759\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5944 - accuracy: 0.7953 - val_loss: 0.5302 - val_accuracy: 0.8149\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5893 - accuracy: 0.7980 - val_loss: 0.5236 - val_accuracy: 0.8153\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5849 - accuracy: 0.7976 - val_loss: 0.5445 - val_accuracy: 0.8098\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5855 - accuracy: 0.7992 - val_loss: 0.5403 - val_accuracy: 0.8089\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5837 - accuracy: 0.8004 - val_loss: 0.5489 - val_accuracy: 0.8096\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5787 - accuracy: 0.8005 - val_loss: 0.5612 - val_accuracy: 0.8045\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5697 - accuracy: 0.8040 - val_loss: 0.5202 - val_accuracy: 0.8192\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 0.5695 - accuracy: 0.8061 - val_loss: 0.5333 - val_accuracy: 0.8182\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5698 - accuracy: 0.8054 - val_loss: 0.6015 - val_accuracy: 0.7954\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5676 - accuracy: 0.8049 - val_loss: 0.5281 - val_accuracy: 0.8185\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5635 - accuracy: 0.8066 - val_loss: 0.5270 - val_accuracy: 0.8173\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5585 - accuracy: 0.8090 - val_loss: 0.5103 - val_accuracy: 0.8211\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5558 - accuracy: 0.8094 - val_loss: 0.5670 - val_accuracy: 0.8057\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5606 - accuracy: 0.8080 - val_loss: 0.5153 - val_accuracy: 0.8193\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5513 - accuracy: 0.8124 - val_loss: 0.5340 - val_accuracy: 0.8157\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5477 - accuracy: 0.8112 - val_loss: 0.5692 - val_accuracy: 0.8069\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5475 - accuracy: 0.8120 - val_loss: 0.5321 - val_accuracy: 0.8184\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5478 - accuracy: 0.8111 - val_loss: 0.5062 - val_accuracy: 0.8265\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5408 - accuracy: 0.8142 - val_loss: 0.6117 - val_accuracy: 0.7953\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5376 - accuracy: 0.8158 - val_loss: 0.5015 - val_accuracy: 0.8281\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5338 - accuracy: 0.8174 - val_loss: 0.5261 - val_accuracy: 0.8212\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5361 - accuracy: 0.8161 - val_loss: 0.5120 - val_accuracy: 0.8250\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5321 - accuracy: 0.8189 - val_loss: 0.5199 - val_accuracy: 0.8232\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5330 - accuracy: 0.8184 - val_loss: 0.4933 - val_accuracy: 0.8314\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5250 - accuracy: 0.8201 - val_loss: 0.5736 - val_accuracy: 0.8067\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5292 - accuracy: 0.8192 - val_loss: 0.5148 - val_accuracy: 0.8269\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5214 - accuracy: 0.8224 - val_loss: 0.4984 - val_accuracy: 0.8316\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5231 - accuracy: 0.8231 - val_loss: 0.5347 - val_accuracy: 0.8175\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5181 - accuracy: 0.8216 - val_loss: 0.5222 - val_accuracy: 0.8238\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5211 - accuracy: 0.8200 - val_loss: 0.4957 - val_accuracy: 0.8326\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5147 - accuracy: 0.8246 - val_loss: 0.4784 - val_accuracy: 0.8368\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5120 - accuracy: 0.8232 - val_loss: 0.5077 - val_accuracy: 0.8295\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5122 - accuracy: 0.8236 - val_loss: 0.4923 - val_accuracy: 0.8334\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5097 - accuracy: 0.8260 - val_loss: 0.5076 - val_accuracy: 0.8297\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.5090 - accuracy: 0.8279 - val_loss: 0.5002 - val_accuracy: 0.8300\n",
      "Epoch 113/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5042 - accuracy: 0.8282 - val_loss: 0.4924 - val_accuracy: 0.8315\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.5073 - accuracy: 0.8264 - val_loss: 0.4593 - val_accuracy: 0.8437\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5019 - accuracy: 0.8284 - val_loss: 0.5238 - val_accuracy: 0.8227\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 0.5042 - accuracy: 0.8271 - val_loss: 0.4630 - val_accuracy: 0.8435\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4986 - accuracy: 0.8285 - val_loss: 0.4540 - val_accuracy: 0.8467\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4956 - accuracy: 0.8295 - val_loss: 0.5257 - val_accuracy: 0.8251\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4911 - accuracy: 0.8313 - val_loss: 0.5138 - val_accuracy: 0.8259\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.4944 - accuracy: 0.8296 - val_loss: 0.4658 - val_accuracy: 0.8415\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4916 - accuracy: 0.8305 - val_loss: 0.4739 - val_accuracy: 0.8406\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4891 - accuracy: 0.8323 - val_loss: 0.4746 - val_accuracy: 0.8378\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4862 - accuracy: 0.8323 - val_loss: 0.4810 - val_accuracy: 0.8347\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4817 - accuracy: 0.8344 - val_loss: 0.5065 - val_accuracy: 0.8303\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4820 - accuracy: 0.8344 - val_loss: 0.4639 - val_accuracy: 0.8440\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 0.4908 - accuracy: 0.8336 - val_loss: 0.4589 - val_accuracy: 0.8458\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4818 - accuracy: 0.8360 - val_loss: 0.4526 - val_accuracy: 0.8462\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4811 - accuracy: 0.8340 - val_loss: 0.4851 - val_accuracy: 0.8373\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4730 - accuracy: 0.8377 - val_loss: 0.4820 - val_accuracy: 0.8399\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4731 - accuracy: 0.8372 - val_loss: 0.4491 - val_accuracy: 0.8485\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4796 - accuracy: 0.8350 - val_loss: 0.4546 - val_accuracy: 0.8481\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4668 - accuracy: 0.8391 - val_loss: 0.4753 - val_accuracy: 0.8368\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4681 - accuracy: 0.8379 - val_loss: 0.4601 - val_accuracy: 0.8454\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4799 - accuracy: 0.8365 - val_loss: 0.4644 - val_accuracy: 0.8398\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4682 - accuracy: 0.8408 - val_loss: 0.4244 - val_accuracy: 0.8546\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4681 - accuracy: 0.8404 - val_loss: 0.4477 - val_accuracy: 0.8519\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4697 - accuracy: 0.8389 - val_loss: 0.4704 - val_accuracy: 0.8416\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 14s 19ms/step - loss: 0.4649 - accuracy: 0.8410 - val_loss: 0.4585 - val_accuracy: 0.8463\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4618 - accuracy: 0.8425 - val_loss: 0.4406 - val_accuracy: 0.8534\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 14s 19ms/step - loss: 0.4604 - accuracy: 0.8430 - val_loss: 0.4233 - val_accuracy: 0.8571\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4605 - accuracy: 0.8430 - val_loss: 0.4348 - val_accuracy: 0.8528\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4610 - accuracy: 0.8418 - val_loss: 0.4681 - val_accuracy: 0.8422\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4563 - accuracy: 0.8440 - val_loss: 0.4343 - val_accuracy: 0.8539\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 14s 19ms/step - loss: 0.4535 - accuracy: 0.8444 - val_loss: 0.4294 - val_accuracy: 0.8529\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4574 - accuracy: 0.8430 - val_loss: 0.4616 - val_accuracy: 0.8459\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4517 - accuracy: 0.8443 - val_loss: 0.4513 - val_accuracy: 0.8469\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4457 - accuracy: 0.8463 - val_loss: 0.4601 - val_accuracy: 0.8468\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4568 - accuracy: 0.8432 - val_loss: 0.4387 - val_accuracy: 0.8504\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4464 - accuracy: 0.8475 - val_loss: 0.5099 - val_accuracy: 0.8296\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4463 - accuracy: 0.8468 - val_loss: 0.4390 - val_accuracy: 0.8510\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4453 - accuracy: 0.8485 - val_loss: 0.4491 - val_accuracy: 0.8505\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4397 - accuracy: 0.8487 - val_loss: 0.4780 - val_accuracy: 0.8408\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4398 - accuracy: 0.8505 - val_loss: 0.4494 - val_accuracy: 0.8480\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4398 - accuracy: 0.8486 - val_loss: 0.4328 - val_accuracy: 0.8561\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4372 - accuracy: 0.8496 - val_loss: 0.4622 - val_accuracy: 0.8466\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4371 - accuracy: 0.8497 - val_loss: 0.4594 - val_accuracy: 0.8477\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4420 - accuracy: 0.8478 - val_loss: 0.4369 - val_accuracy: 0.8530\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4424 - accuracy: 0.8477 - val_loss: 0.4334 - val_accuracy: 0.8556\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4329 - accuracy: 0.8513 - val_loss: 0.4625 - val_accuracy: 0.8472\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4384 - accuracy: 0.8499 - val_loss: 0.4440 - val_accuracy: 0.8485\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4349 - accuracy: 0.8500 - val_loss: 0.4195 - val_accuracy: 0.8584\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4289 - accuracy: 0.8518 - val_loss: 0.4813 - val_accuracy: 0.8427\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4326 - accuracy: 0.8520 - val_loss: 0.4379 - val_accuracy: 0.8524\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4271 - accuracy: 0.8531 - val_loss: 0.4537 - val_accuracy: 0.8465\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4307 - accuracy: 0.8527 - val_loss: 0.4406 - val_accuracy: 0.8496\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4247 - accuracy: 0.8553 - val_loss: 0.4641 - val_accuracy: 0.8444\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4275 - accuracy: 0.8541 - val_loss: 0.4654 - val_accuracy: 0.8473\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4259 - accuracy: 0.8546 - val_loss: 0.4191 - val_accuracy: 0.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4253 - accuracy: 0.8539 - val_loss: 0.4619 - val_accuracy: 0.8477\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4290 - accuracy: 0.8521 - val_loss: 0.4458 - val_accuracy: 0.8515\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4244 - accuracy: 0.8556 - val_loss: 0.4200 - val_accuracy: 0.8612\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4204 - accuracy: 0.8562 - val_loss: 0.4515 - val_accuracy: 0.8480\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4195 - accuracy: 0.8558 - val_loss: 0.4471 - val_accuracy: 0.8518\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4180 - accuracy: 0.8563 - val_loss: 0.4159 - val_accuracy: 0.8585\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4124 - accuracy: 0.8570 - val_loss: 0.4482 - val_accuracy: 0.8511\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4193 - accuracy: 0.8567 - val_loss: 0.4340 - val_accuracy: 0.8542\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4177 - accuracy: 0.8569 - val_loss: 0.3874 - val_accuracy: 0.8707\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4124 - accuracy: 0.8597 - val_loss: 0.4134 - val_accuracy: 0.8649\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4145 - accuracy: 0.8572 - val_loss: 0.3825 - val_accuracy: 0.8699\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4131 - accuracy: 0.8585 - val_loss: 0.4107 - val_accuracy: 0.8634\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4189 - accuracy: 0.8563 - val_loss: 0.4046 - val_accuracy: 0.8646\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4071 - accuracy: 0.8604 - val_loss: 0.3916 - val_accuracy: 0.8705\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4105 - accuracy: 0.8599 - val_loss: 0.4364 - val_accuracy: 0.8513\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4097 - accuracy: 0.8610 - val_loss: 0.4220 - val_accuracy: 0.8561\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4115 - accuracy: 0.8600 - val_loss: 0.4549 - val_accuracy: 0.8476\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.4063 - accuracy: 0.8597 - val_loss: 0.4046 - val_accuracy: 0.8641\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.4096 - accuracy: 0.8611 - val_loss: 0.4461 - val_accuracy: 0.8522\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4026 - accuracy: 0.8639 - val_loss: 0.3969 - val_accuracy: 0.8655\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4092 - accuracy: 0.8586 - val_loss: 0.4309 - val_accuracy: 0.8578\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4033 - accuracy: 0.8617 - val_loss: 0.4171 - val_accuracy: 0.8608\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4008 - accuracy: 0.8636 - val_loss: 0.4422 - val_accuracy: 0.8532\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4054 - accuracy: 0.8622 - val_loss: 0.4171 - val_accuracy: 0.8617\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4018 - accuracy: 0.8627 - val_loss: 0.4229 - val_accuracy: 0.8571\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3959 - accuracy: 0.8657 - val_loss: 0.4046 - val_accuracy: 0.8663\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3966 - accuracy: 0.8651 - val_loss: 0.3894 - val_accuracy: 0.8696\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3981 - accuracy: 0.8624 - val_loss: 0.3943 - val_accuracy: 0.8674\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3952 - accuracy: 0.8648 - val_loss: 0.4428 - val_accuracy: 0.8532\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3911 - accuracy: 0.8653 - val_loss: 0.4014 - val_accuracy: 0.8656\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3919 - accuracy: 0.8660 - val_loss: 0.4060 - val_accuracy: 0.8640\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3949 - accuracy: 0.8633 - val_loss: 0.4082 - val_accuracy: 0.8648\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3929 - accuracy: 0.8645 - val_loss: 0.3901 - val_accuracy: 0.8682\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3898 - accuracy: 0.8668 - val_loss: 0.4002 - val_accuracy: 0.8683\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3957 - accuracy: 0.8646 - val_loss: 0.3935 - val_accuracy: 0.8677\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3926 - accuracy: 0.8646 - val_loss: 0.3991 - val_accuracy: 0.8690\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3923 - accuracy: 0.8672 - val_loss: 0.4000 - val_accuracy: 0.8664\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3883 - accuracy: 0.8669 - val_loss: 0.3932 - val_accuracy: 0.8688\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3896 - accuracy: 0.8657 - val_loss: 0.3940 - val_accuracy: 0.8702\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3844 - accuracy: 0.8692 - val_loss: 0.4065 - val_accuracy: 0.8652\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3876 - accuracy: 0.8669 - val_loss: 0.3979 - val_accuracy: 0.8666\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3840 - accuracy: 0.8696 - val_loss: 0.4147 - val_accuracy: 0.8629\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3893 - accuracy: 0.8659 - val_loss: 0.4055 - val_accuracy: 0.8652\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3889 - accuracy: 0.8659 - val_loss: 0.4074 - val_accuracy: 0.8639\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3842 - accuracy: 0.8693 - val_loss: 0.3882 - val_accuracy: 0.8688\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3834 - accuracy: 0.8705 - val_loss: 0.4382 - val_accuracy: 0.8549\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3835 - accuracy: 0.8676 - val_loss: 0.4395 - val_accuracy: 0.8507\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3771 - accuracy: 0.8710 - val_loss: 0.4090 - val_accuracy: 0.8626\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3779 - accuracy: 0.8711 - val_loss: 0.4195 - val_accuracy: 0.8634\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3791 - accuracy: 0.8708 - val_loss: 0.3983 - val_accuracy: 0.8676\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3781 - accuracy: 0.8704 - val_loss: 0.3822 - val_accuracy: 0.8764\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3769 - accuracy: 0.8706 - val_loss: 0.4054 - val_accuracy: 0.8675\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3770 - accuracy: 0.8694 - val_loss: 0.4086 - val_accuracy: 0.8646\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3786 - accuracy: 0.8706 - val_loss: 0.3876 - val_accuracy: 0.8734\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3780 - accuracy: 0.8704 - val_loss: 0.3832 - val_accuracy: 0.8710\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3778 - accuracy: 0.8708 - val_loss: 0.3659 - val_accuracy: 0.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3679 - accuracy: 0.8726 - val_loss: 0.3936 - val_accuracy: 0.8688\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3712 - accuracy: 0.8716 - val_loss: 0.3845 - val_accuracy: 0.8717\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3694 - accuracy: 0.8722 - val_loss: 0.3965 - val_accuracy: 0.8711\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3720 - accuracy: 0.8739 - val_loss: 0.4082 - val_accuracy: 0.8644\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3701 - accuracy: 0.8726 - val_loss: 0.3687 - val_accuracy: 0.8778\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3710 - accuracy: 0.8732 - val_loss: 0.3777 - val_accuracy: 0.8743\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3699 - accuracy: 0.8736 - val_loss: 0.3865 - val_accuracy: 0.8717\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3635 - accuracy: 0.8751 - val_loss: 0.3714 - val_accuracy: 0.8745\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3694 - accuracy: 0.8743 - val_loss: 0.3985 - val_accuracy: 0.8670\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3730 - accuracy: 0.8722 - val_loss: 0.3956 - val_accuracy: 0.8665\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3668 - accuracy: 0.8753 - val_loss: 0.4005 - val_accuracy: 0.8656\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3660 - accuracy: 0.8736 - val_loss: 0.4011 - val_accuracy: 0.8691\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3664 - accuracy: 0.8746 - val_loss: 0.3962 - val_accuracy: 0.8688\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3629 - accuracy: 0.8753 - val_loss: 0.3795 - val_accuracy: 0.8771\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3617 - accuracy: 0.8766 - val_loss: 0.4044 - val_accuracy: 0.8673\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3615 - accuracy: 0.8765 - val_loss: 0.3815 - val_accuracy: 0.8723\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3607 - accuracy: 0.8772 - val_loss: 0.3891 - val_accuracy: 0.8699\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3602 - accuracy: 0.8772 - val_loss: 0.3880 - val_accuracy: 0.8712\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3625 - accuracy: 0.8755 - val_loss: 0.3808 - val_accuracy: 0.8754\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3673 - accuracy: 0.8738 - val_loss: 0.3737 - val_accuracy: 0.8768\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3612 - accuracy: 0.8755 - val_loss: 0.3746 - val_accuracy: 0.8755\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3572 - accuracy: 0.8773 - val_loss: 0.3917 - val_accuracy: 0.8697\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3614 - accuracy: 0.8762 - val_loss: 0.3714 - val_accuracy: 0.8765\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3618 - accuracy: 0.8762 - val_loss: 0.3945 - val_accuracy: 0.8709\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3544 - accuracy: 0.8775 - val_loss: 0.3741 - val_accuracy: 0.8779\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3579 - accuracy: 0.8775 - val_loss: 0.3947 - val_accuracy: 0.8689\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3585 - accuracy: 0.8772 - val_loss: 0.3956 - val_accuracy: 0.8687\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3590 - accuracy: 0.8774 - val_loss: 0.3675 - val_accuracy: 0.8783\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3532 - accuracy: 0.8800 - val_loss: 0.3822 - val_accuracy: 0.8721\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3508 - accuracy: 0.8793 - val_loss: 0.4258 - val_accuracy: 0.8632\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3553 - accuracy: 0.8785 - val_loss: 0.3886 - val_accuracy: 0.8738\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3503 - accuracy: 0.8796 - val_loss: 0.3827 - val_accuracy: 0.8743\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3483 - accuracy: 0.8806 - val_loss: 0.3972 - val_accuracy: 0.8678\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.3519 - accuracy: 0.8795 - val_loss: 0.3813 - val_accuracy: 0.8730\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3550 - accuracy: 0.8801 - val_loss: 0.3830 - val_accuracy: 0.8753\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3524 - accuracy: 0.8778 - val_loss: 0.3641 - val_accuracy: 0.8800\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3479 - accuracy: 0.8812 - val_loss: 0.3644 - val_accuracy: 0.8784\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3539 - accuracy: 0.8795 - val_loss: 0.3932 - val_accuracy: 0.8710\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3481 - accuracy: 0.8797 - val_loss: 0.3709 - val_accuracy: 0.8760\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3486 - accuracy: 0.8803 - val_loss: 0.3716 - val_accuracy: 0.8761\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3498 - accuracy: 0.8793 - val_loss: 0.3538 - val_accuracy: 0.8831\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3457 - accuracy: 0.8801 - val_loss: 0.3707 - val_accuracy: 0.8795\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3453 - accuracy: 0.8824 - val_loss: 0.3739 - val_accuracy: 0.8749\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3467 - accuracy: 0.8809 - val_loss: 0.3691 - val_accuracy: 0.8777\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3443 - accuracy: 0.8821 - val_loss: 0.3809 - val_accuracy: 0.8755\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.3439 - accuracy: 0.8826 - val_loss: 0.3715 - val_accuracy: 0.8766\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3438 - accuracy: 0.8824 - val_loss: 0.3726 - val_accuracy: 0.8785\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.3466 - accuracy: 0.8820 - val_loss: 0.3851 - val_accuracy: 0.8736\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3479 - accuracy: 0.8818 - val_loss: 0.3866 - val_accuracy: 0.8707\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3480 - accuracy: 0.8812 - val_loss: 0.3648 - val_accuracy: 0.8812\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3388 - accuracy: 0.8833 - val_loss: 0.3944 - val_accuracy: 0.8707\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3405 - accuracy: 0.8827 - val_loss: 0.3588 - val_accuracy: 0.8797\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3376 - accuracy: 0.8842 - val_loss: 0.3631 - val_accuracy: 0.8801\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3416 - accuracy: 0.8821 - val_loss: 0.3630 - val_accuracy: 0.8788\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3433 - accuracy: 0.8814 - val_loss: 0.3751 - val_accuracy: 0.8798\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3376 - accuracy: 0.8843 - val_loss: 0.4056 - val_accuracy: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3376 - accuracy: 0.8834 - val_loss: 0.3787 - val_accuracy: 0.8765\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3355 - accuracy: 0.8844 - val_loss: 0.3789 - val_accuracy: 0.8794\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3394 - accuracy: 0.8840 - val_loss: 0.4032 - val_accuracy: 0.8684\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3385 - accuracy: 0.8818 - val_loss: 0.3966 - val_accuracy: 0.8710\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3384 - accuracy: 0.8848 - val_loss: 0.3689 - val_accuracy: 0.8799\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3339 - accuracy: 0.8844 - val_loss: 0.4050 - val_accuracy: 0.8670\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3334 - accuracy: 0.8857 - val_loss: 0.3680 - val_accuracy: 0.8802\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3323 - accuracy: 0.8859 - val_loss: 0.3628 - val_accuracy: 0.8808\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3392 - accuracy: 0.8841 - val_loss: 0.3649 - val_accuracy: 0.8799\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3313 - accuracy: 0.8869 - val_loss: 0.3718 - val_accuracy: 0.8795\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3367 - accuracy: 0.8843 - val_loss: 0.3750 - val_accuracy: 0.8778\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3374 - accuracy: 0.8844 - val_loss: 0.4037 - val_accuracy: 0.8699\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3321 - accuracy: 0.8848 - val_loss: 0.3614 - val_accuracy: 0.8805\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3355 - accuracy: 0.8854 - val_loss: 0.3721 - val_accuracy: 0.8773\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3304 - accuracy: 0.8847 - val_loss: 0.3795 - val_accuracy: 0.8761\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3275 - accuracy: 0.8874 - val_loss: 0.3821 - val_accuracy: 0.8764\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3284 - accuracy: 0.8867 - val_loss: 0.4050 - val_accuracy: 0.8688\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3252 - accuracy: 0.8879 - val_loss: 0.3630 - val_accuracy: 0.8820\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3251 - accuracy: 0.8883 - val_loss: 0.3691 - val_accuracy: 0.8809\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3308 - accuracy: 0.8857 - val_loss: 0.3775 - val_accuracy: 0.8778\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3281 - accuracy: 0.8877 - val_loss: 0.4067 - val_accuracy: 0.8714\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3300 - accuracy: 0.8876 - val_loss: 0.3740 - val_accuracy: 0.8780\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3251 - accuracy: 0.8873 - val_loss: 0.4068 - val_accuracy: 0.8704\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3220 - accuracy: 0.8886 - val_loss: 0.3959 - val_accuracy: 0.8734\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3254 - accuracy: 0.8889 - val_loss: 0.3870 - val_accuracy: 0.8726\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3298 - accuracy: 0.8872 - val_loss: 0.3499 - val_accuracy: 0.8854\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3253 - accuracy: 0.8887 - val_loss: 0.3534 - val_accuracy: 0.8836\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3269 - accuracy: 0.8882 - val_loss: 0.3536 - val_accuracy: 0.8833\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3243 - accuracy: 0.8886 - val_loss: 0.3735 - val_accuracy: 0.8790\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3241 - accuracy: 0.8893 - val_loss: 0.3578 - val_accuracy: 0.8835\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3265 - accuracy: 0.8879 - val_loss: 0.3837 - val_accuracy: 0.8741\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3242 - accuracy: 0.8881 - val_loss: 0.4004 - val_accuracy: 0.8690\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3209 - accuracy: 0.8891 - val_loss: 0.3408 - val_accuracy: 0.8855\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3199 - accuracy: 0.8907 - val_loss: 0.3462 - val_accuracy: 0.8864\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3142 - accuracy: 0.8918 - val_loss: 0.3683 - val_accuracy: 0.8754\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3222 - accuracy: 0.8889 - val_loss: 0.3578 - val_accuracy: 0.8820\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3225 - accuracy: 0.8891 - val_loss: 0.3807 - val_accuracy: 0.8775\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3189 - accuracy: 0.8893 - val_loss: 0.3770 - val_accuracy: 0.8768\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3159 - accuracy: 0.8912 - val_loss: 0.3687 - val_accuracy: 0.8798\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3174 - accuracy: 0.8883 - val_loss: 0.3645 - val_accuracy: 0.8810\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3226 - accuracy: 0.8890 - val_loss: 0.3711 - val_accuracy: 0.8785\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3171 - accuracy: 0.8899 - val_loss: 0.3641 - val_accuracy: 0.8824\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.3191 - accuracy: 0.8897 - val_loss: 0.4075 - val_accuracy: 0.8673\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3188 - accuracy: 0.8896 - val_loss: 0.3726 - val_accuracy: 0.8772\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3156 - accuracy: 0.8910 - val_loss: 0.3995 - val_accuracy: 0.8730\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3148 - accuracy: 0.8916 - val_loss: 0.3659 - val_accuracy: 0.8821\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3186 - accuracy: 0.8896 - val_loss: 0.3728 - val_accuracy: 0.8792\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 16s 20ms/step - loss: 0.3150 - accuracy: 0.8921 - val_loss: 0.3482 - val_accuracy: 0.8857\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3167 - accuracy: 0.8920 - val_loss: 0.3801 - val_accuracy: 0.8788\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3120 - accuracy: 0.8926 - val_loss: 0.3710 - val_accuracy: 0.8806\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3116 - accuracy: 0.8925 - val_loss: 0.3466 - val_accuracy: 0.8860\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3142 - accuracy: 0.8914 - val_loss: 0.3787 - val_accuracy: 0.8786\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3114 - accuracy: 0.8928 - val_loss: 0.3517 - val_accuracy: 0.8859\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3166 - accuracy: 0.8918 - val_loss: 0.3654 - val_accuracy: 0.8777\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3130 - accuracy: 0.8922 - val_loss: 0.3968 - val_accuracy: 0.8697\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3128 - accuracy: 0.8928 - val_loss: 0.3498 - val_accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3139 - accuracy: 0.8917 - val_loss: 0.3702 - val_accuracy: 0.8790\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3124 - accuracy: 0.8919 - val_loss: 0.3699 - val_accuracy: 0.8792\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3066 - accuracy: 0.8936 - val_loss: 0.3590 - val_accuracy: 0.8818\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3144 - accuracy: 0.8921 - val_loss: 0.3386 - val_accuracy: 0.8890\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3105 - accuracy: 0.8926 - val_loss: 0.3544 - val_accuracy: 0.8852\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3095 - accuracy: 0.8940 - val_loss: 0.3618 - val_accuracy: 0.8829\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3066 - accuracy: 0.8936 - val_loss: 0.3750 - val_accuracy: 0.8799\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3071 - accuracy: 0.8949 - val_loss: 0.3516 - val_accuracy: 0.8856\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3069 - accuracy: 0.8948 - val_loss: 0.3717 - val_accuracy: 0.8809\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 14s 19ms/step - loss: 0.3123 - accuracy: 0.8934 - val_loss: 0.3429 - val_accuracy: 0.8891\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3068 - accuracy: 0.8948 - val_loss: 0.3522 - val_accuracy: 0.8844\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3053 - accuracy: 0.8948 - val_loss: 0.3396 - val_accuracy: 0.8902\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3041 - accuracy: 0.8949 - val_loss: 0.3437 - val_accuracy: 0.8883\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3059 - accuracy: 0.8956 - val_loss: 0.3479 - val_accuracy: 0.8871\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3048 - accuracy: 0.8959 - val_loss: 0.3603 - val_accuracy: 0.8847\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3053 - accuracy: 0.8958 - val_loss: 0.3674 - val_accuracy: 0.8826\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3067 - accuracy: 0.8953 - val_loss: 0.3359 - val_accuracy: 0.8884\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3075 - accuracy: 0.8942 - val_loss: 0.3342 - val_accuracy: 0.8904\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.3051 - accuracy: 0.8949 - val_loss: 0.3466 - val_accuracy: 0.8891\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3032 - accuracy: 0.8960 - val_loss: 0.3398 - val_accuracy: 0.8902\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3022 - accuracy: 0.8955 - val_loss: 0.3552 - val_accuracy: 0.8859\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3020 - accuracy: 0.8967 - val_loss: 0.3685 - val_accuracy: 0.8809\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3022 - accuracy: 0.8961 - val_loss: 0.3625 - val_accuracy: 0.8825\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2965 - accuracy: 0.8988 - val_loss: 0.3498 - val_accuracy: 0.8856\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3080 - accuracy: 0.8933 - val_loss: 0.3556 - val_accuracy: 0.8849\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3006 - accuracy: 0.8960 - val_loss: 0.3554 - val_accuracy: 0.8848\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3010 - accuracy: 0.8977 - val_loss: 0.3559 - val_accuracy: 0.8820\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3028 - accuracy: 0.8950 - val_loss: 0.3361 - val_accuracy: 0.8904\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2957 - accuracy: 0.8985 - val_loss: 0.3888 - val_accuracy: 0.8753\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.3051 - accuracy: 0.8955 - val_loss: 0.3405 - val_accuracy: 0.8895\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.3014 - accuracy: 0.8962 - val_loss: 0.3566 - val_accuracy: 0.8811\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2969 - accuracy: 0.8973 - val_loss: 0.3570 - val_accuracy: 0.8841\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2982 - accuracy: 0.8964 - val_loss: 0.3603 - val_accuracy: 0.8823\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2976 - accuracy: 0.8977 - val_loss: 0.3847 - val_accuracy: 0.8770\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.3002 - accuracy: 0.8967 - val_loss: 0.3562 - val_accuracy: 0.8860\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2976 - accuracy: 0.8982 - val_loss: 0.3627 - val_accuracy: 0.8832\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2939 - accuracy: 0.8994 - val_loss: 0.3716 - val_accuracy: 0.8778\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2977 - accuracy: 0.8973 - val_loss: 0.3397 - val_accuracy: 0.8889\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2940 - accuracy: 0.8983 - val_loss: 0.3519 - val_accuracy: 0.8870\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2978 - accuracy: 0.8971 - val_loss: 0.3578 - val_accuracy: 0.8853\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2953 - accuracy: 0.8977 - val_loss: 0.3941 - val_accuracy: 0.8766\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2971 - accuracy: 0.8972 - val_loss: 0.3530 - val_accuracy: 0.8874\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2943 - accuracy: 0.8985 - val_loss: 0.3678 - val_accuracy: 0.8819\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2978 - accuracy: 0.8972 - val_loss: 0.3430 - val_accuracy: 0.8875\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2951 - accuracy: 0.8969 - val_loss: 0.3469 - val_accuracy: 0.8891\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2958 - accuracy: 0.8983 - val_loss: 0.3970 - val_accuracy: 0.8736\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2938 - accuracy: 0.8978 - val_loss: 0.3901 - val_accuracy: 0.8748\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2975 - accuracy: 0.8986 - val_loss: 0.3551 - val_accuracy: 0.8880\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2951 - accuracy: 0.8991 - val_loss: 0.3657 - val_accuracy: 0.8836\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 0.2939 - accuracy: 0.8996 - val_loss: 0.3355 - val_accuracy: 0.8878\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2952 - accuracy: 0.8998 - val_loss: 0.3772 - val_accuracy: 0.8784\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2933 - accuracy: 0.8994 - val_loss: 0.3712 - val_accuracy: 0.8790\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2901 - accuracy: 0.9002 - val_loss: 0.3589 - val_accuracy: 0.8867\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2894 - accuracy: 0.9007 - val_loss: 0.3496 - val_accuracy: 0.8867\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.2944 - accuracy: 0.8989 - val_loss: 0.3366 - val_accuracy: 0.8919\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2924 - accuracy: 0.9003 - val_loss: 0.3401 - val_accuracy: 0.8895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2864 - accuracy: 0.9019 - val_loss: 0.3560 - val_accuracy: 0.8833\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2941 - accuracy: 0.8969 - val_loss: 0.3451 - val_accuracy: 0.8891\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2911 - accuracy: 0.8990 - val_loss: 0.3601 - val_accuracy: 0.8880\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2885 - accuracy: 0.8997 - val_loss: 0.3379 - val_accuracy: 0.8897\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 13s 17ms/step - loss: 0.2886 - accuracy: 0.8996 - val_loss: 0.3385 - val_accuracy: 0.8910\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2857 - accuracy: 0.9017 - val_loss: 0.3482 - val_accuracy: 0.8890\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 15s 19ms/step - loss: 0.2866 - accuracy: 0.9011 - val_loss: 0.3486 - val_accuracy: 0.8857\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.2900 - accuracy: 0.9002 - val_loss: 0.3630 - val_accuracy: 0.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f526259cb20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fit\n",
    "model_10.fit(it_train, steps_per_epoch=steps, epochs=400, validation_data=(x_test, y_test),callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "058c511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8586 - accuracy: 0.6994\n",
      "Test accuracy: 0.699400007724762\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on the test set\n",
    "loss, accuracy = model_10.evaluate(x_test, y_test)\n",
    "\n",
    "# print the accuracy of the model on the test set\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440cd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generator\n",
    "datagen_100 = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it_train_100 = datagen.flow(x_train_100, y_train_100, batch_size=64)\n",
    "# fit model\n",
    "steps = int(x_train_100.shape[0] / 64)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model_100 = Sequential()\n",
    "model_100.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model_100.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_100.add(MaxPooling2D((2, 2)))\n",
    "model_100.add(Dropout(0.2))\n",
    "model_100.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_100.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_100.add(MaxPooling2D((2, 2)))\n",
    "model_100.add(Dropout(0.3))\n",
    "model_100.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_100.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_100.add(MaxPooling2D((2, 2)))\n",
    "model_100.add(Dropout(0.4))\n",
    "model_100.add(Flatten())\n",
    "model_100.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_100.add(Dropout(0.5))\n",
    "model_100.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_100_gpu.{epoch:02d}.h5', save_freq='epoch')\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the epoch number.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.001\n",
    "    if (epoch>130 and epoch<=200):\n",
    "        learning_rate=0.0005\n",
    "    if (epoch>200 and epoch<=250):\n",
    "        learning_rate=0.00025\n",
    "    if (epoch>250 and epoch<=300):\n",
    "        learning_rate=0.000125\n",
    "    if (epoch>300 and epoch<=350):\n",
    "        learning_rate=0.0000625\n",
    "    if (epoch>300 and epoch<=400):\n",
    "        learning_rate=0.00003125\n",
    "    return learning_rate\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model_100.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Model Fit\n",
    "#model_100.fit(it_train_100, steps_per_epoch=steps, epochs=400, validation_data=(x_test_100, y_test_100), callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0dbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9054 - accuracy: 0.4883\n",
      "Test accuracy: 0.48829999566078186\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the pre-saved model\n",
    "model_100 = load_model('model_100_gpu.105.h5')\n",
    "\n",
    "# test the accuracy of the model on the test set\n",
    "loss, accuracy = model_100.evaluate(x_test_100, y_test_100)\n",
    "\n",
    "# print the accuracy of the model on the test set\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "082e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0005\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule_new(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the epoch number.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.0005\n",
    "    if (epoch>50 and epoch<=100):\n",
    "        learning_rate=0.00025\n",
    "    if (epoch>100 and epoch<=150):\n",
    "        learning_rate=0.000125\n",
    "    if (epoch>150 and epoch<=200):\n",
    "        learning_rate=0.0000625\n",
    "    if (epoch>200 and epoch<=250):\n",
    "        learning_rate=0.00003125\n",
    "    if (epoch>300 and epoch<=400):\n",
    "        learning_rate=0.000015625\n",
    "    return learning_rate\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule_new)\n",
    "\n",
    "model_100.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Model Fit\n",
    "#model_100.fit(it_train_100, steps_per_epoch=steps, epochs=400, validation_data=(x_test_100, y_test_100), callbacks=[lr_scheduler,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f22e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5624 - accuracy: 0.5890\n",
      "Test accuracy: 0.5889999866485596\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the pre-saved model\n",
    "model_100 = load_model('model_100_gpu.400.h5')\n",
    "\n",
    "# test the accuracy of the model on the test set\n",
    "loss, accuracy = model_100.evaluate(x_test_100, y_test_100)\n",
    "\n",
    "# print the accuracy of the model on the test set\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f450c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
