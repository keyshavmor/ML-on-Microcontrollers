{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ad436e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "GPU (s):\n",
      "0.04393045699544018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:23:46.724509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 15:23:46.724790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 15:23:46.724986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 15:23:46.725242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 15:23:46.725446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-09 15:23:46.725598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 5802 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "305e8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75d7c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "data_path = 'cifar-10-batches-py/'\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(data_path + 'data_batch_' + str(i))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "496d35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data = unpickle(data_path + 'test_batch')[b'data']\n",
    "test_data = test_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(unpickle(data_path + 'test_batch')[b'labels'])\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "data_path = 'cifar-100-python/'\n",
    "train_data_100 = unpickle(data_path + 'train')[b'data']\n",
    "train_data_100 = train_data_100.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data_100 = unpickle(data_path + 'test')[b'data']\n",
    "test_data_100 = test_data_100.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels_100 = np.array(unpickle(data_path + 'train')[b'fine_labels'])\n",
    "test_labels_100 = np.array(unpickle(data_path + 'test')[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d5a372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 10\n",
      "Number of training samples: 50000\n",
      "\n",
      "CIFAR-100\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 100\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "print(\"CIFAR-10\")\n",
    "print(\"Number of features:\", train_data.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "print(\"Number of training samples:\", train_data.shape[0])\n",
    "\n",
    "# Print the number of features, classes, and training samples for CIFAR-100\n",
    "print(\"\\nCIFAR-100\")\n",
    "print(\"Number of features:\", train_data_100.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels_100)))\n",
    "print(\"Number of training samples:\", train_data_100.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e294dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=42)\n",
    "test_data, test_labels = shuffle(test_data, test_labels, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = train_data.astype('float32') / 255.0\n",
    "x_test = test_data.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(zoom_range=[0.5,1.5],\n",
    "                             brightness_range=[0.5,1.0],\n",
    "                             shear_range=0.5,\n",
    "                             width_shift_range=0.5, \n",
    "                             height_shift_range=0.5,\n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76844843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_23 (Quantize  (None, 32, 32, 3)        3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_conv2d_159 (QuantizeW  (None, 32, 32, 32)       963       \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_160 (QuantizeW  (None, 32, 32, 32)       9315      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_69 (Qua  (None, 16, 16, 32)       1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_161 (QuantizeW  (None, 16, 16, 64)       18627     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_162 (QuantizeW  (None, 16, 16, 64)       37059     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_70 (Qua  (None, 8, 8, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_163 (QuantizeW  (None, 8, 8, 128)        74115     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_164 (QuantizeW  (None, 8, 8, 128)        147843    \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_71 (Qua  (None, 4, 4, 128)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_24 (QuantizeW  (None, 2048)             1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_48 (QuantizeWra  (None, 128)              262277    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_49 (QuantizeWra  (None, 10)               1295      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551,501\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 931\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 3.0961 - accuracy: 0.3550 - val_loss: 1.6327 - val_accuracy: 0.4814 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.5743 - accuracy: 0.5037 - val_loss: 1.5085 - val_accuracy: 0.5319 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.3981 - accuracy: 0.5809 - val_loss: 1.4446 - val_accuracy: 0.5799 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.2657 - accuracy: 0.6354 - val_loss: 1.1754 - val_accuracy: 0.6673 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.1505 - accuracy: 0.6770 - val_loss: 1.2481 - val_accuracy: 0.6430 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.0847 - accuracy: 0.7024 - val_loss: 1.1692 - val_accuracy: 0.6773 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.0084 - accuracy: 0.7286 - val_loss: 1.1674 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.9592 - accuracy: 0.7457 - val_loss: 1.0216 - val_accuracy: 0.7245 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.9111 - accuracy: 0.7607 - val_loss: 0.9764 - val_accuracy: 0.7458 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.8648 - accuracy: 0.7783 - val_loss: 0.9945 - val_accuracy: 0.7447 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.8337 - accuracy: 0.7868 - val_loss: 0.9218 - val_accuracy: 0.7610 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.7874 - accuracy: 0.8021 - val_loss: 1.1416 - val_accuracy: 0.7026 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.7604 - accuracy: 0.8117 - val_loss: 0.9672 - val_accuracy: 0.7527 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.7282 - accuracy: 0.8237 - val_loss: 0.9974 - val_accuracy: 0.7482 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.7125 - accuracy: 0.8281 - val_loss: 0.9961 - val_accuracy: 0.7589 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6935 - accuracy: 0.8352 - val_loss: 1.0537 - val_accuracy: 0.7389 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6681 - accuracy: 0.8445 - val_loss: 0.9470 - val_accuracy: 0.7641 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6436 - accuracy: 0.8525 - val_loss: 0.9731 - val_accuracy: 0.7680 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6230 - accuracy: 0.8595 - val_loss: 1.0551 - val_accuracy: 0.7528 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.6131 - accuracy: 0.8636 - val_loss: 0.9777 - val_accuracy: 0.7597 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5904 - accuracy: 0.8713 - val_loss: 0.9579 - val_accuracy: 0.7774 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5852 - accuracy: 0.8752 - val_loss: 1.1379 - val_accuracy: 0.7481 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5550 - accuracy: 0.8825 - val_loss: 0.9771 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5472 - accuracy: 0.8858 - val_loss: 1.0829 - val_accuracy: 0.7476 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5425 - accuracy: 0.8879 - val_loss: 0.9919 - val_accuracy: 0.7744 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5207 - accuracy: 0.8952 - val_loss: 1.2827 - val_accuracy: 0.7349 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5349 - accuracy: 0.8941 - val_loss: 1.0950 - val_accuracy: 0.7527 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.5020 - accuracy: 0.9007 - val_loss: 1.0161 - val_accuracy: 0.7704 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4891 - accuracy: 0.9079 - val_loss: 1.0674 - val_accuracy: 0.7797 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4993 - accuracy: 0.9061 - val_loss: 1.1556 - val_accuracy: 0.7700 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4811 - accuracy: 0.9113 - val_loss: 1.1428 - val_accuracy: 0.7585 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4787 - accuracy: 0.9121 - val_loss: 1.1091 - val_accuracy: 0.7561 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4436 - accuracy: 0.9198 - val_loss: 1.0485 - val_accuracy: 0.7821 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4574 - accuracy: 0.9180 - val_loss: 1.0897 - val_accuracy: 0.7746 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4459 - accuracy: 0.9224 - val_loss: 1.3073 - val_accuracy: 0.7458 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4456 - accuracy: 0.9235 - val_loss: 1.0792 - val_accuracy: 0.7728 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4298 - accuracy: 0.9262 - val_loss: 1.1621 - val_accuracy: 0.7695 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4354 - accuracy: 0.9272 - val_loss: 1.1745 - val_accuracy: 0.7690 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.4111 - accuracy: 0.9321 - val_loss: 1.2240 - val_accuracy: 0.7595 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.4228 - accuracy: 0.9299 - val_loss: 1.1166 - val_accuracy: 0.7807 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4034 - accuracy: 0.9353 - val_loss: 1.1674 - val_accuracy: 0.7668 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4202 - accuracy: 0.9322 - val_loss: 1.2169 - val_accuracy: 0.7703 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.3844 - accuracy: 0.9379 - val_loss: 1.2542 - val_accuracy: 0.7694 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.2106 - accuracy: 0.9711 - val_loss: 0.7903 - val_accuracy: 0.8067 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0987 - accuracy: 0.9858 - val_loss: 0.8219 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.0842 - accuracy: 0.9888 - val_loss: 0.8218 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0767 - accuracy: 0.9894 - val_loss: 0.8410 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0702 - accuracy: 0.9911 - val_loss: 0.8660 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0663 - accuracy: 0.9918 - val_loss: 0.8663 - val_accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0626 - accuracy: 0.9924 - val_loss: 0.9070 - val_accuracy: 0.8124 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0597 - accuracy: 0.9928 - val_loss: 0.9105 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0574 - accuracy: 0.9932 - val_loss: 0.9139 - val_accuracy: 0.8102 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0547 - accuracy: 0.9938 - val_loss: 0.9442 - val_accuracy: 0.8117 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0526 - accuracy: 0.9943 - val_loss: 0.9353 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0509 - accuracy: 0.9943 - val_loss: 0.9410 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0505 - accuracy: 0.9945 - val_loss: 0.9759 - val_accuracy: 0.8088 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0472 - accuracy: 0.9950 - val_loss: 0.9561 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0476 - accuracy: 0.9949 - val_loss: 0.9813 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0459 - accuracy: 0.9953 - val_loss: 0.9750 - val_accuracy: 0.8106 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0447 - accuracy: 0.9954 - val_loss: 0.9993 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0444 - accuracy: 0.9957 - val_loss: 1.0113 - val_accuracy: 0.8108 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0425 - accuracy: 0.9958 - val_loss: 1.0048 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0415 - accuracy: 0.9962 - val_loss: 1.0395 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0406 - accuracy: 0.9961 - val_loss: 0.9995 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0408 - accuracy: 0.9962 - val_loss: 1.0461 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0398 - accuracy: 0.9965 - val_loss: 1.0990 - val_accuracy: 0.8092 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0402 - accuracy: 0.9962 - val_loss: 1.0358 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0377 - accuracy: 0.9968 - val_loss: 1.0770 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0381 - accuracy: 0.9968 - val_loss: 1.0533 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0387 - accuracy: 0.9966 - val_loss: 1.0965 - val_accuracy: 0.8088 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0379 - accuracy: 0.9967 - val_loss: 1.0796 - val_accuracy: 0.8076 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0376 - accuracy: 0.9965 - val_loss: 1.0910 - val_accuracy: 0.8146 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0376 - accuracy: 0.9968 - val_loss: 1.1037 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0357 - accuracy: 0.9971 - val_loss: 1.1209 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0344 - accuracy: 0.9971 - val_loss: 1.1384 - val_accuracy: 0.8117 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0397 - accuracy: 0.9965 - val_loss: 1.4785 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0400 - accuracy: 0.9972 - val_loss: 1.0831 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0330 - accuracy: 0.9974 - val_loss: 1.1462 - val_accuracy: 0.8099 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0331 - accuracy: 0.9975 - val_loss: 1.0958 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0364 - accuracy: 0.9969 - val_loss: 1.2966 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0341 - accuracy: 0.9975 - val_loss: 1.1325 - val_accuracy: 0.8116 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0309 - accuracy: 0.9976 - val_loss: 1.1224 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0317 - accuracy: 0.9977 - val_loss: 1.1897 - val_accuracy: 0.8090 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0327 - accuracy: 0.9973 - val_loss: 1.3782 - val_accuracy: 0.8058 - lr: 0.0010\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0389 - accuracy: 0.9969 - val_loss: 1.4670 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0415 - accuracy: 0.9968 - val_loss: 1.4608 - val_accuracy: 0.8011 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0336 - accuracy: 0.9977 - val_loss: 1.2428 - val_accuracy: 0.8032 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0337 - accuracy: 0.9972 - val_loss: 1.3702 - val_accuracy: 0.8051 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0321 - accuracy: 0.9979 - val_loss: 1.2197 - val_accuracy: 0.8117 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0363 - accuracy: 0.9973 - val_loss: 1.1342 - val_accuracy: 0.8115 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0307 - accuracy: 0.9979 - val_loss: 1.1575 - val_accuracy: 0.8122 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0291 - accuracy: 0.9980 - val_loss: 1.1333 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0315 - accuracy: 0.9974 - val_loss: 1.2364 - val_accuracy: 0.8085 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0329 - accuracy: 0.9973 - val_loss: 1.3549 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0275 - accuracy: 0.9982 - val_loss: 1.1742 - val_accuracy: 0.8097 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0324 - accuracy: 0.9978 - val_loss: 1.3924 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0308 - accuracy: 0.9978 - val_loss: 1.1661 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0278 - accuracy: 0.9980 - val_loss: 1.2435 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0318 - accuracy: 0.9979 - val_loss: 1.1763 - val_accuracy: 0.8106 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0332 - accuracy: 0.9976 - val_loss: 1.3087 - val_accuracy: 0.8082 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef90a8a3d30>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "regularizer = tf.keras.regularizers.OrthogonalRegularizer(factor=0.01)\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', \n",
    "                    input_shape=(32, 32, 3)))\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(128, activation='relu', kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,l2=0.1)))\n",
    "model_10.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT.h5', save_freq='epoch')\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
    "                                factor=0.1,\n",
    "                                patience=10,\n",
    "                                verbose=0,\n",
    "                                mode=\"max\",\n",
    "                                min_delta=0.0001,\n",
    "                                cooldown=0,\n",
    "                                min_lr=0.001)\n",
    "\n",
    "# Convert the model to a quantization aware model\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(model_10)\n",
    "\n",
    "quant_aware_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "quant_aware_model.summary()\n",
    "\n",
    "# Train and evaluate the quantization aware model\n",
    "quant_aware_model.fit(x_train,y_train, batch_size=64,epochs=100,validation_data=(x_test, y_test),callbacks=[checkpoint_callback,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "affed6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization aware training loss:  1.3086711168289185\n",
      "Quantization aware training accuracy:  0.8082000017166138\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "quant_loss, quant_acc = quant_aware_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Quantization aware training loss: ', quant_loss)\n",
    "print('Quantization aware training accuracy: ', quant_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "058c511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_159_layer_call_fn, conv2d_159_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_160_layer_call_fn, conv2d_160_layer_call_and_return_conditional_losses while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpximppup8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpximppup8/assets\n",
      "/home/themandalorian/anaconda3/envs/dl-gpu/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-05-09 15:54:35.268762: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-09 15:54:35.268792: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-09 15:54:35.268936: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpximppup8\n",
      "2023-05-09 15:54:35.274487: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-09 15:54:35.274510: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpximppup8\n",
      "2023-05-09 15:54:35.290449: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-09 15:54:35.373653: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpximppup8\n",
      "2023-05-09 15:54:35.395402: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 126464 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8_qat = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "440cd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "571456"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"cifar10_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cb0dbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_conv2d_159_input:0\n",
      "shape: [ 1 32 32  3]\n",
      "type: <class 'numpy.uint8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter('cifar10_qat_int8.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "082e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(x_test),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(x_test)):\n",
    "    val_batch = x_test[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4f22e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 80.72%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f450c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
