{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad436e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow==2.11 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: keras==2.11 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.24.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (66.0.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (2.11.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (16.0.0)\n",
      "Requirement already satisfied: packaging in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (23.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (3.8.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (23.5.9)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.54.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (3.19.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorflow==2.11) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.18.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.29.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.26.15)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/themandalorian/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 22:54:45.766885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 22:54:46.997885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-14 22:54:46.997940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-14 22:54:46.997944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "!pip install tensorflow==2.11 keras==2.11\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305e8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d7c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "data_path = 'cifar-10-batches-py/'\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(data_path + 'data_batch_' + str(i))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496d35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data = unpickle(data_path + 'test_batch')[b'data']\n",
    "test_data = test_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(unpickle(data_path + 'test_batch')[b'labels'])\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "data_path = 'cifar-100-python/'\n",
    "train_data_100 = unpickle(data_path + 'train')[b'data']\n",
    "train_data_100 = train_data_100.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_data_100 = unpickle(data_path + 'test')[b'data']\n",
    "test_data_100 = test_data_100.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "train_labels_100 = np.array(unpickle(data_path + 'train')[b'fine_labels'])\n",
    "test_labels_100 = np.array(unpickle(data_path + 'test')[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5a372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 10\n",
      "Number of training samples: 50000\n",
      "\n",
      "CIFAR-100\n",
      "Number of features: (32, 32, 3)\n",
      "Number of classes: 100\n",
      "Number of training samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features, classes, and training samples for CIFAR-10\n",
    "print(\"CIFAR-10\")\n",
    "print(\"Number of features:\", train_data.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n",
    "print(\"Number of training samples:\", train_data.shape[0])\n",
    "\n",
    "# Print the number of features, classes, and training samples for CIFAR-100\n",
    "print(\"\\nCIFAR-100\")\n",
    "print(\"Number of features:\", train_data_100.shape[1:])\n",
    "print(\"Number of classes:\", len(np.unique(train_labels_100)))\n",
    "print(\"Number of training samples:\", train_data_100.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e294dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: scikit-learn in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=42)\n",
    "test_data, test_labels = shuffle(test_data, test_labels, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = train_data.astype('float32') / 255.0\n",
    "x_test = test_data.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(train_labels, num_classes=10)\n",
    "y_test = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(zoom_range=[0.5,1.5],\n",
    "                             brightness_range=[0.5,1.0],\n",
    "                             shear_range=0.5,\n",
    "                             width_shift_range=0.5, \n",
    "                             height_shift_range=0.5,\n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76844843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_17 (Quantize  (None, 32, 32, 3)        3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_conv2d_159 (QuantizeW  (None, 32, 32, 32)       963       \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_160 (QuantizeW  (None, 32, 32, 32)       9315      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_80 (Qua  (None, 8, 8, 32)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_161 (QuantizeW  (None, 8, 8, 64)         18627     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_162 (QuantizeW  (None, 8, 8, 64)         37059     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_81 (Qua  (None, 2, 2, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_163 (QuantizeW  (None, 2, 2, 128)        74115     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_164 (QuantizeW  (None, 2, 2, 128)        147843    \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_82 (Qua  (None, 1, 1, 128)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_15 (QuantizeW  (None, 128)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_31 (QuantizeWra  (None, 64)               8261      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_32 (QuantizeWra  (None, 32)               2085      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_33 (QuantizeWra  (None, 10)               335       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,610\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 936\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "782/782 [==============================] - 39s 48ms/step - loss: 3.7608 - accuracy: 0.3983 - val_loss: 1.4206 - val_accuracy: 0.5287 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 1.3005 - accuracy: 0.5654 - val_loss: 1.1565 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 1.0956 - accuracy: 0.6353 - val_loss: 1.1492 - val_accuracy: 0.6253 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.9649 - accuracy: 0.6805 - val_loss: 0.9581 - val_accuracy: 0.6781 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.8650 - accuracy: 0.7169 - val_loss: 0.9464 - val_accuracy: 0.6993 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.7953 - accuracy: 0.7423 - val_loss: 0.8900 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.7294 - accuracy: 0.7675 - val_loss: 0.8704 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.6728 - accuracy: 0.7856 - val_loss: 0.8303 - val_accuracy: 0.7431 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.6203 - accuracy: 0.8070 - val_loss: 0.8249 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 0.5825 - accuracy: 0.8186 - val_loss: 0.9116 - val_accuracy: 0.7306 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.5405 - accuracy: 0.8316 - val_loss: 0.8469 - val_accuracy: 0.7468 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 37s 47ms/step - loss: 0.5013 - accuracy: 0.8467 - val_loss: 0.8093 - val_accuracy: 0.7585 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.4618 - accuracy: 0.8584 - val_loss: 0.8616 - val_accuracy: 0.7495 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.4321 - accuracy: 0.8699 - val_loss: 0.8499 - val_accuracy: 0.7585 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.4016 - accuracy: 0.8769 - val_loss: 0.8699 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.3732 - accuracy: 0.8890 - val_loss: 0.8986 - val_accuracy: 0.7503 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.3467 - accuracy: 0.8975 - val_loss: 0.9054 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.3167 - accuracy: 0.9086 - val_loss: 1.0184 - val_accuracy: 0.7377 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 0.3028 - accuracy: 0.9127 - val_loss: 0.8938 - val_accuracy: 0.7564 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2746 - accuracy: 0.9219 - val_loss: 0.9549 - val_accuracy: 0.7606 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2553 - accuracy: 0.9278 - val_loss: 1.0918 - val_accuracy: 0.7516 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2427 - accuracy: 0.9335 - val_loss: 1.0535 - val_accuracy: 0.7529 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2239 - accuracy: 0.9380 - val_loss: 1.0673 - val_accuracy: 0.7614 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2071 - accuracy: 0.9445 - val_loss: 1.1149 - val_accuracy: 0.7572 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.2110 - accuracy: 0.9439 - val_loss: 1.1033 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.1957 - accuracy: 0.9485 - val_loss: 1.1082 - val_accuracy: 0.7403 - lr: 0.0010\n",
      "Epoch 27/50\n",
      " 38/782 [>.............................] - ETA: 34s - loss: 0.2045 - accuracy: 0.9457"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m quant_aware_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Train and evaluate the quantization aware model\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mquant_aware_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', \n",
    "                    input_shape=(32, 32, 3)))\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((4, 4)))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((4, 4)))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(64, activation='relu', kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,l2=0.1)))\n",
    "model_10.add(Dense(32, activation='relu', kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,l2=0.1)))\n",
    "model_10.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT.h5', save_freq='epoch')\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
    "                                factor=0.1,\n",
    "                                patience=10,\n",
    "                                verbose=0,\n",
    "                                mode=\"max\",\n",
    "                                min_delta=0.0001,\n",
    "                                cooldown=0,\n",
    "                                min_lr=0.001)\n",
    "\n",
    "# Convert the model to a quantization aware model\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(model_10)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "quant_aware_model.summary()\n",
    "\n",
    "# Train and evaluate the quantization aware model\n",
    "quant_aware_model.fit(x_train,y_train, batch_size=64,epochs=50,validation_data=(x_test, y_test),callbacks=[checkpoint_callback,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "affed6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization aware training loss:  1.1021994352340698\n",
      "Quantization aware training accuracy:  0.7612000107765198\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "quant_loss, quant_acc = quant_aware_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Quantization aware training loss: ', quant_loss)\n",
    "print('Quantization aware training accuracy: ', quant_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "058c511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_159_layer_call_fn, conv2d_159_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_160_layer_call_fn while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7yvskgue/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7yvskgue/assets\n",
      "/home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-05-15 01:29:42.391262: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-15 01:29:42.391293: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-15 01:29:42.391445: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp7yvskgue\n",
      "2023-05-15 01:29:42.397527: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-15 01:29:42.397544: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp7yvskgue\n",
      "2023-05-15 01:29:42.416555: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-15 01:29:42.522883: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp7yvskgue\n",
      "2023-05-15 01:29:42.549214: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 157770 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8_qat = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "440cd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "319088"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"cifar10_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb0dbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_conv2d_159_input:0\n",
      "shape: [ 1 32 32  3]\n",
      "type: <class 'numpy.uint8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter('cifar10_qat_int8.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "082e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(x_test),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(x_test)):\n",
    "    val_batch = x_test[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f22e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 76.14%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "369f450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       1762      \n",
      " 159 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       18466     \n",
      " 160 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 8, 8, 32)         1         \n",
      " ling2d_80 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         36930     \n",
      " 161 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         73794     \n",
      " 162 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 2, 2, 64)         1         \n",
      " ling2d_81 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        147586    \n",
      " 163 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        295042    \n",
      " 164 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 1, 1, 128)        1         \n",
      " ling2d_82 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 128)              1         \n",
      " _15 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 64)               16450     \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 32)               4130      \n",
      " 2 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 10)               652       \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,816\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 297,142\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 32s 39ms/step - loss: 3.7607 - accuracy: 0.4000 - val_loss: 1.5246 - val_accuracy: 0.4806\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 1.2753 - accuracy: 0.5663 - val_loss: 1.1419 - val_accuracy: 0.6108\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 1.0920 - accuracy: 0.6342 - val_loss: 1.0513 - val_accuracy: 0.6460\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.9688 - accuracy: 0.6772 - val_loss: 0.9844 - val_accuracy: 0.6745\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.8927 - accuracy: 0.7042 - val_loss: 0.9539 - val_accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05bbeaf850>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "        'block_size': (1, 1),\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model_10, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model.summary()\n",
    "\n",
    "pruned_model_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT_St_Pruning.h5', save_freq='epoch')\n",
    "\n",
    "# Train and evaluate the pruned model\n",
    "# if you get an error like train_function -> train_function\n",
    "# just run the cell again\n",
    "pruned_model.fit(x_train,y_train, batch_size=64,epochs=5,validation_data=(x_test, y_test),\n",
    "                                      callbacks=[pruned_model_callback,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcc9de25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       1762      \n",
      " 159 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       18466     \n",
      " 160 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 8, 8, 32)         1         \n",
      " ling2d_80 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         36930     \n",
      " 161 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         73794     \n",
      " 162 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 2, 2, 64)         1         \n",
      " ling2d_81 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        147586    \n",
      " 163 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        295042    \n",
      " 164 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 1, 1, 128)        1         \n",
      " ling2d_82 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 128)              1         \n",
      " _15 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 64)               16450     \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 32)               4130      \n",
      " 2 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 10)               652       \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,816\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 297,142\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 32s 38ms/step - loss: 0.8743 - accuracy: 0.7111 - val_loss: 0.9310 - val_accuracy: 0.6909\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.7955 - accuracy: 0.7389 - val_loss: 0.9193 - val_accuracy: 0.7041\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.7300 - accuracy: 0.7636 - val_loss: 0.8488 - val_accuracy: 0.7276\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.6688 - accuracy: 0.7840 - val_loss: 0.8862 - val_accuracy: 0.7234\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.6304 - accuracy: 0.8002 - val_loss: 0.8417 - val_accuracy: 0.7392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f055439b940>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(model_10, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()\n",
    "\n",
    "pruned_model_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT_US_Pruning_Static.h5', save_freq='epoch')\n",
    "\n",
    "# Train and evaluate the pruned model\n",
    "pruned_model_unstructured.fit(x_train,y_train, batch_size=64,epochs=5,validation_data=(x_test, y_test),\n",
    "                                      callbacks=[pruned_model_callback,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "416e27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       1762      \n",
      " 159 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 32, 32, 32)       18466     \n",
      " 160 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 8, 8, 32)         1         \n",
      " ling2d_80 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         36930     \n",
      " 161 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         73794     \n",
      " 162 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 2, 2, 64)         1         \n",
      " ling2d_81 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        147586    \n",
      " 163 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 2, 2, 128)        295042    \n",
      " 164 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 1, 1, 128)        1         \n",
      " ling2d_82 (PruneLowMagnitud                                     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 128)              1         \n",
      " _15 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 64)               16450     \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 32)               4130      \n",
      " 2 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 10)               652       \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,816\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 297,142\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 33s 38ms/step - loss: 0.6555 - accuracy: 0.7891 - val_loss: 0.8447 - val_accuracy: 0.7333\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.6135 - accuracy: 0.8049 - val_loss: 0.8390 - val_accuracy: 0.7406\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.5784 - accuracy: 0.8168 - val_loss: 0.8250 - val_accuracy: 0.7455\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.6791 - accuracy: 0.7849 - val_loss: 0.8676 - val_accuracy: 0.7309\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.6400 - accuracy: 0.8014 - val_loss: 0.8062 - val_accuracy: 0.7508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05bbe2be50>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unstructured pruning with dynamic sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                                    final_sparsity=0.80,\n",
    "                                                                    begin_step=2000,\n",
    "                                                                    end_step=4000,\n",
    "                                                                    frequency=100)\n",
    "\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured_dynamic = tfmot.sparsity.keras.prune_low_magnitude(model_10, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured_dynamic.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured_dynamic.summary()\n",
    "\n",
    "pruned_model_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT_US_Pruning.h5', save_freq='epoch')\n",
    "\n",
    "\n",
    "pruned_model_unstructured_dynamic.fit(x_train,y_train, batch_size=64,epochs=5,validation_data=(x_test, y_test),\n",
    "                                      callbacks=[pruned_model_callback,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99ad23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /home/themandalorian/Git/ML-on-Microcontrollers/keras_model_10_QAT_St_Pruning.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph4fbur2r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmph4fbur2r/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/themandalorian/Git/ML-on-Microcontrollers/model_10_QAT_St_Pruning.tflite\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 01:37:22.687814: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-15 01:37:22.687842: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-15 01:37:22.687985: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmph4fbur2r\n",
      "2023-05-15 01:37:22.690051: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-15 01:37:22.690064: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmph4fbur2r\n",
      "2023-05-15 01:37:22.695589: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-15 01:37:22.720800: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmph4fbur2r\n",
      "2023-05-15 01:37:22.729515: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 41531 microseconds.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /home/themandalorian/Git/ML-on-Microcontrollers/keras_model_10_QAT_US_Pruning_Static.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0ntt0iiv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0ntt0iiv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/themandalorian/Git/ML-on-Microcontrollers/model_10_QAT_US_Pruning_Static.tflite\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 01:37:24.002544: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-15 01:37:24.002571: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-15 01:37:24.002711: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp0ntt0iiv\n",
      "2023-05-15 01:37:24.004736: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-15 01:37:24.004750: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp0ntt0iiv\n",
      "2023-05-15 01:37:24.010137: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-15 01:37:24.034703: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp0ntt0iiv\n",
      "2023-05-15 01:37:24.043895: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 41184 microseconds.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /home/themandalorian/Git/ML-on-Microcontrollers/keras_model_10_QAT_US_Pruning.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_c0ggshd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_c0ggshd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/themandalorian/Git/ML-on-Microcontrollers/model_10_QAT_US_Pruning.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 01:37:25.316766: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-15 01:37:25.316793: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-15 01:37:25.316935: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp_c0ggshd\n",
      "2023-05-15 01:37:25.318940: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-15 01:37:25.318954: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp_c0ggshd\n",
      "2023-05-15 01:37:25.324498: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-15 01:37:25.349832: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp_c0ggshd\n",
      "2023-05-15 01:37:25.358861: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 41925 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pruned_model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "pruned_keras_file = 'keras_model_10_QAT_St_Pruning.h5'\n",
    "tf.keras.models.save_model(pruned_model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "pruned_tflite_file = 'model_10_QAT_St_Pruning.tflite'\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file))\n",
    "\n",
    "# Conversion to TF Lite\n",
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "pruned_keras_file_unstructured = 'keras_model_10_QAT_US_Pruning_Static.h5'\n",
    "tf.keras.models.save_model(pruned_model_unstructured_for_export, pruned_keras_file_unstructured, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured))\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_for_export)\n",
    "pruned_tflite_model_unstructured = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured = 'model_10_QAT_US_Pruning_Static.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured)\n",
    "\n",
    "print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured))\n",
    "\n",
    "# Conversion to Keras Lite\n",
    "pruned_model_unstructured_dynamic_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured_dynamic)\n",
    "\n",
    "pruned_keras_file_unstructured_dynamic = 'keras_model_10_QAT_US_Pruning.h5'\n",
    "tf.keras.models.save_model(pruned_model_unstructured_dynamic_for_export, pruned_keras_file_unstructured_dynamic, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured_dynamic))\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_dynamic_for_export)\n",
    "pruned_tflite_model_unstructured_dynamic = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured_dynamic = 'model_10_QAT_US_Pruning.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured_dynamic, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured_dynamic)\n",
    "\n",
    "print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured_dynamic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f254869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 images.\n",
      "Evaluated on 1000 images.\n",
      "Evaluated on 2000 images.\n",
      "Evaluated on 3000 images.\n",
      "Evaluated on 4000 images.\n",
      "Evaluated on 5000 images.\n",
      "Evaluated on 6000 images.\n",
      "Evaluated on 7000 images.\n",
      "Evaluated on 8000 images.\n",
      "Evaluated on 9000 images.\n",
      "Accuracy of pruned_tflite model is 75.08%\n"
     ]
    }
   ],
   "source": [
    "test_image_indices = range(x_test.shape[0])\n",
    "\n",
    "# Initialize the interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=str(pruned_tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = x_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    if (test_image_index % 1000 == 0):\n",
    "        print(\"Evaluated on %d images.\" % test_image_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of pruned_tflite model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "327a7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 images.\n",
      "Evaluated on 1000 images.\n",
      "Evaluated on 2000 images.\n",
      "Evaluated on 3000 images.\n",
      "Evaluated on 4000 images.\n",
      "Evaluated on 5000 images.\n",
      "Evaluated on 6000 images.\n",
      "Evaluated on 7000 images.\n",
      "Evaluated on 8000 images.\n",
      "Evaluated on 9000 images.\n",
      "Accuracy of pruned tflite unstructured model is 75.08%\n"
     ]
    }
   ],
   "source": [
    "test_image_indices = range(x_test.shape[0])\n",
    "\n",
    "# Initialize the interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=str(pruned_tflite_file_unstructured))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = x_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    if (test_image_index % 1000 == 0):\n",
    "        print(\"Evaluated on %d images.\" % test_image_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of pruned tflite unstructured model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78b40a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 images.\n",
      "Evaluated on 1000 images.\n",
      "Evaluated on 2000 images.\n",
      "Evaluated on 3000 images.\n",
      "Evaluated on 4000 images.\n",
      "Evaluated on 5000 images.\n",
      "Evaluated on 6000 images.\n",
      "Evaluated on 7000 images.\n",
      "Evaluated on 8000 images.\n",
      "Evaluated on 9000 images.\n",
      "Accuracy of pruned tflite unstructured dynamic is 75.08%\n"
     ]
    }
   ],
   "source": [
    "test_image_indices = range(x_test.shape[0])\n",
    "\n",
    "# Initialize the interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=str(pruned_tflite_file_unstructured_dynamic))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = x_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    if (test_image_index % 1000 == 0):\n",
    "        print(\"Evaluated on %d images.\" % test_image_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of pruned tflite unstructured dynamic is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6f452ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_18 (Quantize  (None, 32, 32, 3)        3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_conv2d_159 (QuantizeW  (None, 32, 32, 32)       963       \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_160 (QuantizeW  (None, 32, 32, 32)       9315      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_80 (Qua  (None, 8, 8, 32)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_161 (QuantizeW  (None, 8, 8, 64)         18627     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_162 (QuantizeW  (None, 8, 8, 64)         37059     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_81 (Qua  (None, 2, 2, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_163 (QuantizeW  (None, 2, 2, 128)        74115     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_164 (QuantizeW  (None, 2, 2, 128)        147843    \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_82 (Qua  (None, 1, 1, 128)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_15 (QuantizeW  (None, 128)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_31 (QuantizeWra  (None, 64)               8261      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_32 (QuantizeWra  (None, 32)               2085      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_33 (QuantizeWra  (None, 10)               335       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,610\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 936\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 39s 48ms/step - loss: 0.7041 - accuracy: 0.8191 - val_loss: 0.8526 - val_accuracy: 0.7511\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 37s 47ms/step - loss: 0.5487 - accuracy: 0.8379 - val_loss: 0.8043 - val_accuracy: 0.7574\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.5128 - accuracy: 0.8477 - val_loss: 0.8697 - val_accuracy: 0.7395\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.4935 - accuracy: 0.8519 - val_loss: 0.8215 - val_accuracy: 0.7551\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.4692 - accuracy: 0.8587 - val_loss: 0.8056 - val_accuracy: 0.7622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05bb6d2520>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_10_QAT_Pruning.h5', save_freq='epoch')\n",
    "\n",
    "# train the model\n",
    "pruned_qat_model.fit(x_train,y_train, batch_size=64,epochs=5,validation_data=(x_test, y_test),\n",
    "                                      callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ece1d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_159_layer_call_fn, conv2d_159_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_160_layer_call_fn while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xjidud6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xjidud6/assets\n",
      "/home/themandalorian/anaconda3/envs/mlonmcu_lab2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned QAT TFLite model to: /home/themandalorian/Git/ML-on-Microcontrollers/model_10_QAT_Pruning.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 01:40:57.625552: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-15 01:40:57.625580: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-15 01:40:57.625727: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp0xjidud6\n",
      "2023-05-15 01:40:57.632210: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-15 01:40:57.632233: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp0xjidud6\n",
      "2023-05-15 01:40:57.652742: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-05-15 01:40:57.761252: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp0xjidud6\n",
      "2023-05-15 01:40:57.788706: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 162977 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_qat_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_qat_tflite_file = 'model_10_QAT_Pruning.tflite'\n",
    "\n",
    "with open(pruned_qat_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_qat_tflite_model)\n",
    "\n",
    "print('Saved pruned QAT TFLite model to:', os.path.abspath(pruned_qat_tflite_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fb2bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 images.\n",
      "Evaluated on 1000 images.\n",
      "Evaluated on 2000 images.\n",
      "Evaluated on 3000 images.\n",
      "Evaluated on 4000 images.\n",
      "Evaluated on 5000 images.\n",
      "Evaluated on 6000 images.\n",
      "Evaluated on 7000 images.\n",
      "Evaluated on 8000 images.\n",
      "Evaluated on 9000 images.\n",
      "Accuracy of quantized to int8 model is 76.29%\n"
     ]
    }
   ],
   "source": [
    "test_image_indices = range(x_test.shape[0])\n",
    "\n",
    "# Initialize the interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=str(pruned_qat_tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = x_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    if (test_image_index % 1000 == 0):\n",
    "        print(\"Evaluated on %d images.\" % test_image_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 10000\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f70a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d20a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535388b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7fabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2a80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
